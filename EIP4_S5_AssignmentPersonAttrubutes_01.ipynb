{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP4-S5-AssignmentPersonAttrubutes-01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumarchandan/EIP4/blob/master/EIP4_S5_AssignmentPersonAttrubutes_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "ff886dc3-e1b6-4ffc-c0ab-95e912b8f53b"
      },
      "source": [
        " # mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  hvc_annotations.csv  \u001b[01;34mresized\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54fe35c1-8f01-4b26-dd55-82293e841648"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "c0e48c16-1483-4bb9-b705-d7bef8019a5e"
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>imagequality</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>carryingbag</th>\n",
              "      <th>footwear</th>\n",
              "      <th>emotion</th>\n",
              "      <th>bodypose</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>over-weight</td>\n",
              "      <td>None</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Angry/Serious</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Daily/Office/Work Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>Good</td>\n",
              "      <td>35-45</td>\n",
              "      <td>slightly-overweight</td>\n",
              "      <td>None</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender imagequality    age  ...        emotion        bodypose     image_path\n",
              "0    male      Average  35-45  ...        Neutral  Front-Frontish  resized/1.jpg\n",
              "1  female      Average  35-45  ...  Angry/Serious  Front-Frontish  resized/2.jpg\n",
              "2    male         Good  45-55  ...        Neutral  Front-Frontish  resized/3.jpg\n",
              "3    male         Good  45-55  ...        Neutral  Front-Frontish  resized/4.jpg\n",
              "4  female         Good  35-45  ...        Neutral  Front-Frontish  resized/5.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "outputId": "b1ab9c9b-6265-462c-c281-1d88f7b13e00"
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>image_path</th>\n",
              "      <td>resized/1.jpg</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_female</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_male</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Average</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Good</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_15-25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_25-35</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_35-45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_45-55</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_55+</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_over-weight</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_underweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_None</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Normal</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Happy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Sad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Back</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Side</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  0  ...              4\n",
              "image_path                            resized/1.jpg  ...  resized/5.jpg\n",
              "gender_female                                     0  ...              1\n",
              "gender_male                                       1  ...              0\n",
              "imagequality_Average                              1  ...              0\n",
              "imagequality_Bad                                  0  ...              0\n",
              "imagequality_Good                                 0  ...              1\n",
              "age_15-25                                         0  ...              0\n",
              "age_25-35                                         0  ...              0\n",
              "age_35-45                                         1  ...              1\n",
              "age_45-55                                         0  ...              0\n",
              "age_55+                                           0  ...              0\n",
              "weight_normal-healthy                             1  ...              0\n",
              "weight_over-weight                                0  ...              0\n",
              "weight_slightly-overweight                        0  ...              1\n",
              "weight_underweight                                0  ...              0\n",
              "carryingbag_Daily/Office/Work Bag                 0  ...              0\n",
              "carryingbag_Grocery/Home/Plastic Bag              1  ...              0\n",
              "carryingbag_None                                  0  ...              1\n",
              "footwear_CantSee                                  0  ...              1\n",
              "footwear_Fancy                                    0  ...              0\n",
              "footwear_Normal                                   1  ...              0\n",
              "emotion_Angry/Serious                             0  ...              0\n",
              "emotion_Happy                                     0  ...              0\n",
              "emotion_Neutral                                   1  ...              1\n",
              "emotion_Sad                                       0  ...              0\n",
              "bodypose_Back                                     0  ...              0\n",
              "bodypose_Front-Frontish                           1  ...              1\n",
              "bodypose_Side                                     0  ...              0\n",
              "\n",
              "[28 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "img_rows, img_cols = 224, 224\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True, augmentation=None):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        if self.augmentation is not None:\n",
        "          image = self.augmentation.flow(images, shuffle=False).next()\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0579565-4c5d-4b6d-8894-93e18bb6f972"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.2)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10858, 28), (2715, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "c2757f7d-bc2c-4f59-ba07-621c29007b26"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>gender_female</th>\n",
              "      <th>gender_male</th>\n",
              "      <th>imagequality_Average</th>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <th>imagequality_Good</th>\n",
              "      <th>age_15-25</th>\n",
              "      <th>age_25-35</th>\n",
              "      <th>age_35-45</th>\n",
              "      <th>age_45-55</th>\n",
              "      <th>age_55+</th>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <th>weight_over-weight</th>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <th>weight_underweight</th>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <th>carryingbag_None</th>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <th>footwear_Normal</th>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <th>emotion_Happy</th>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <th>emotion_Sad</th>\n",
              "      <th>bodypose_Back</th>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <th>bodypose_Side</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2395</th>\n",
              "      <td>resized/2396.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2447</th>\n",
              "      <td>resized/2448.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>resized/424.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5042</th>\n",
              "      <td>resized/5043.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10691</th>\n",
              "      <td>resized/10693.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              image_path  gender_female  ...  bodypose_Front-Frontish  bodypose_Side\n",
              "2395    resized/2396.jpg              0  ...                        1              0\n",
              "2447    resized/2448.jpg              0  ...                        0              1\n",
              "423      resized/424.jpg              0  ...                        0              1\n",
              "5042    resized/5043.jpg              0  ...                        0              0\n",
              "10691  resized/10693.jpg              0  ...                        0              0\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aHcHGaIJU68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "8d01a212-4167-41fa-9089-9e4d15c69cfe"
      },
      "source": [
        "train_df.iloc[1370]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "image_path                              resized/2503.jpg\n",
              "gender_female                                          0\n",
              "gender_male                                            1\n",
              "imagequality_Average                                   0\n",
              "imagequality_Bad                                       1\n",
              "imagequality_Good                                      0\n",
              "age_15-25                                              0\n",
              "age_25-35                                              1\n",
              "age_35-45                                              0\n",
              "age_45-55                                              0\n",
              "age_55+                                                0\n",
              "weight_normal-healthy                                  1\n",
              "weight_over-weight                                     0\n",
              "weight_slightly-overweight                             0\n",
              "weight_underweight                                     0\n",
              "carryingbag_Daily/Office/Work Bag                      0\n",
              "carryingbag_Grocery/Home/Plastic Bag                   1\n",
              "carryingbag_None                                       0\n",
              "footwear_CantSee                                       0\n",
              "footwear_Fancy                                         0\n",
              "footwear_Normal                                        1\n",
              "emotion_Angry/Serious                                  1\n",
              "emotion_Happy                                          0\n",
              "emotion_Neutral                                        0\n",
              "emotion_Sad                                            0\n",
              "bodypose_Back                                          0\n",
              "bodypose_Front-Frontish                                1\n",
              "bodypose_Side                                          0\n",
              "Name: 2502, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9F1CvBOJgUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "22e96f3f-69f3-4625-db05-04e1b6914746"
      },
      "source": [
        "from IPython.display import Image\n",
        "path = train_df.image_path[4675]\n",
        "Image(filename=path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\nO4Ad687F0+SSZ6+DrxlB8x+dVFFFUZBRRRQAUUUUAFFFFAH/2Q==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "# Use some data augmentation\n",
        "train_gen = PersonDataGenerator(\n",
        "    train_df,\n",
        "    batch_size=32)\n",
        "\n",
        "valid_gen = PersonDataGenerator(\n",
        "    val_df,\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "3d0825a1-268c-43d1-e484-37732c2973f7"
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 5,\n",
              " 'bag': 3,\n",
              " 'emotion': 4,\n",
              " 'footwear': 3,\n",
              " 'gender': 2,\n",
              " 'image_quality': 3,\n",
              " 'pose': 3,\n",
              " 'weight': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHV0B30csWqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03W8Pagg_Ppp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55a6438c-0755-45ba-aa50-bcf9bfd89837"
      },
      "source": [
        "# backbone = VGG16(\n",
        "#     weights=\"imagenet\", \n",
        "#     include_top=False, \n",
        "#     input_tensor=Input(shape=(224, 224, 3))\n",
        "# )\n",
        "backbone = Sequential()\n",
        "\n",
        "backbone.add(Convolution2D(16, (3, 3),dilation_rate=(2, 2),input_shape=(224, 224, 3))) #220\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "backbone.add(Convolution2D(16, (3, 3),strides=(2,2))) #110\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "backbone.add(Convolution2D(32, (3, 3),dilation_rate=(2, 2))) #106\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "backbone.add(Convolution2D(32, 3, 3)) #104\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "backbone.add(Convolution2D(48, (3, 3),strides=(2,2))) #52\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "backbone.add(Convolution2D(48, (3, 3),dilation_rate=(2, 2))) #48\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "#backbone.add(Dropout(0.2))\n",
        "backbone.add(Convolution2D(64, 3, 3)) #46\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "backbone.add(Convolution2D(64, (3, 3),strides=(2,2))) #23\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "backbone.add(Convolution2D(96, (3, 3),dilation_rate=(2, 2))) #19\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "backbone.add(Convolution2D(96, (3, 3),strides=(2,2))) #9\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "backbone.add(Convolution2D(128, (3, 3),dilation_rate=(2, 2))) #5\n",
        "backbone.add(BatchNormalization())\n",
        "backbone.add(Activation('relu'))\n",
        "backbone.add(Dropout(0.2))\n",
        "backbone.add(GlobalAveragePooling2D(name='avg_pool'))\n",
        "\n",
        "\n",
        "neck = backbone.output\n",
        "# neck = Flatten(name=\"flatten\")(neck)\n",
        "# neck = Dense(512, activation=\"relu\")(neck)\n",
        "\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    # neck = Dropout(0.2)(in_layer)\n",
        "    # neck = Dense(128, activation=\"relu\")(neck)\n",
        "    # neck = Dropout(0.3)(in_layer)\n",
        "    # neck = Dense(128, activation=\"relu\")(neck)\n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_tower(neck))\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs=backbone.input, \n",
        "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        ")\n",
        "\n",
        "#\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "conv2d_1_input (InputLayer)     (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 220, 220, 16) 448         conv2d_1_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 220, 220, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 220, 220, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 220, 220, 16) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 16) 2320        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 109, 109, 16) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 105, 105, 32) 4640        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 105, 105, 32) 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 105, 105, 32) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 105, 105, 32) 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 103, 103, 32) 9248        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 103, 103, 32) 128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 103, 103, 32) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 103, 103, 32) 0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 51, 51, 48)   13872       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 51, 51, 48)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 51, 51, 48)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 51, 51, 48)   0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 47, 47, 48)   20784       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 47, 47, 48)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 47, 47, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 47, 47, 48)   0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 45, 45, 64)   27712       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 45, 45, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 45, 45, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 45, 45, 64)   0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 22, 22, 64)   36928       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 22, 22, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 22, 22, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 22, 22, 64)   0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 18, 18, 96)   55392       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 18, 18, 96)   384         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 18, 18, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 18, 18, 96)   0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 8, 8, 96)     83040       dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 8, 8, 96)     384         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 96)     0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 8, 8, 96)     0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 4, 4, 128)    110720      dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 4, 4, 128)    512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 4, 4, 128)    0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 4, 4, 128)    0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 128)          0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Dense)           (None, 2)            258         avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "image_quality_output (Dense)    (None, 3)            387         avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "age_output (Dense)              (None, 5)            645         avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "weight_output (Dense)           (None, 4)            516         avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bag_output (Dense)              (None, 3)            387         avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "footwear_output (Dense)         (None, 3)            387         avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pose_output (Dense)             (None, 3)            387         avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "emotion_output (Dense)          (None, 4)            516         avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 371,147\n",
            "Trainable params: 369,867\n",
            "Non-trainable params: 1,280\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPG9C2eA1zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# losses = {\n",
        "# \t\"gender_output\": \"binary_crossentropy\",\n",
        "# \t\"image_quality_output\": \"categorical_crossentropy\",\n",
        "# \t\"age_output\": \"categorical_crossentropy\",\n",
        "# \t\"weight_output\": \"categorical_crossentropy\",\n",
        "\n",
        "# }\n",
        "# loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0}\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  lr = 1e-3\n",
        "  if epoch > 150:\n",
        "    lr = round(0.1 * 1/(1 + 0.319 * epoch), 10)\n",
        "  elif epoch > 110:\n",
        "    lr = round(0.1 * 1/(1 + 0.319 * epoch), 10)\n",
        "  elif epoch > 20:\n",
        "    lr = 1e-3\n",
        "  elif epoch > 0:\n",
        "    lr = 1e-2\n",
        "  \n",
        "  print('Learning rate: ', lr)\n",
        "  return lr\n",
        "\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "lr=0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw2ZRIQ7BW-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxv41EyNmN4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "cc99aa4c-bc84-4080-8b7f-cbbd12699f69"
      },
      "source": [
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Checkpoints\n",
        "model_type='Assign5'\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "gender_filepath = os.path.join(save_dir, \"gender.h5\")\n",
        "imgQuality_filepath = os.path.join(save_dir, \"imgQuality.h5\")\n",
        "age_filepath = os.path.join(save_dir, \"age.h5\")\n",
        "weight_filepath = os.path.join(save_dir, \"weight.h5\")\n",
        "bag_filepath = os.path.join(save_dir, \"bag.h5\")\n",
        "footwear_filepath = os.path.join(save_dir, \"footwear.h5\")\n",
        "pose_filepath = os.path.join(save_dir, \"pose.h5\")\n",
        "emotion_filepath = os.path.join(save_dir, \"emotion.h5\")\n",
        "\n",
        "gender_checkpoint = ModelCheckpoint(filepath=gender_filepath,\n",
        "                             monitor='val_gender_output_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "imgQuality_checkpoint = ModelCheckpoint(filepath=imgQuality_filepath,\n",
        "                             monitor='val_image_quality_output_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "age_checkpoint = ModelCheckpoint(filepath=age_filepath,\n",
        "                             monitor='val_age_output_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "weight_checkpoint = ModelCheckpoint(filepath=weight_filepath,\n",
        "                             monitor='val_weight_output_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "bag_checkpoint = ModelCheckpoint(filepath=bag_filepath,\n",
        "                             monitor='val_bag_output_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "footwear_checkpoint = ModelCheckpoint(filepath=footwear_filepath,\n",
        "                             monitor='val_footwear_output_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "pose_checkpoint = ModelCheckpoint(filepath=pose_filepath,\n",
        "                             monitor='val_pose_output_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "emotion_checkpoint = ModelCheckpoint(filepath=emotion_filepath,\n",
        "                             monitor='val_emotion_output_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 3,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "# reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "#                               factor = 0.2,\n",
        "#                               patience = 3,\n",
        "#                               verbose = 1,\n",
        "#                               min_delta = 0.00001)\n",
        "\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler, verbose=1) #LearningRateScheduler(lr_schedule)\n",
        "\n",
        "callbacks = [lr_reducer, lr_scheduler]\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIBxuqtOztu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41e1e88a-6088-452b-ef78-5dffd343c1bd"
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=10, \n",
        "    epochs=100,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 49s 144ms/step - loss: 7.9013 - gender_output_loss: 0.6631 - image_quality_output_loss: 1.0036 - age_output_loss: 1.4433 - weight_output_loss: 1.0049 - bag_output_loss: 0.9304 - footwear_output_loss: 0.9731 - pose_output_loss: 0.9417 - emotion_output_loss: 0.9411 - gender_output_acc: 0.6009 - image_quality_output_acc: 0.5352 - age_output_acc: 0.3797 - weight_output_acc: 0.6209 - bag_output_acc: 0.5471 - footwear_output_acc: 0.5399 - pose_output_acc: 0.6130 - emotion_output_acc: 0.6925 - val_loss: 9.6947 - val_gender_output_loss: 0.6687 - val_image_quality_output_loss: 1.1450 - val_age_output_loss: 1.6873 - val_weight_output_loss: 1.3605 - val_bag_output_loss: 1.0590 - val_footwear_output_loss: 1.8410 - val_pose_output_loss: 0.9575 - val_emotion_output_loss: 0.9756 - val_gender_output_acc: 0.6112 - val_image_quality_output_acc: 0.5558 - val_age_output_acc: 0.3876 - val_weight_output_acc: 0.6295 - val_bag_output_acc: 0.5632 - val_footwear_output_acc: 0.4933 - val_pose_output_acc: 0.5584 - val_emotion_output_acc: 0.7054\n",
            "Epoch 2/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 7.7868 - gender_output_loss: 0.6555 - image_quality_output_loss: 0.9943 - age_output_loss: 1.4311 - weight_output_loss: 0.9935 - bag_output_loss: 0.9166 - footwear_output_loss: 0.9536 - pose_output_loss: 0.9253 - emotion_output_loss: 0.9170 - gender_output_acc: 0.6004 - image_quality_output_acc: 0.5480 - age_output_acc: 0.3869 - weight_output_acc: 0.6343 - bag_output_acc: 0.5521 - footwear_output_acc: 0.5511 - pose_output_acc: 0.6152 - emotion_output_acc: 0.7124 - val_loss: 8.0200 - val_gender_output_loss: 0.7109 - val_image_quality_output_loss: 0.9742 - val_age_output_loss: 1.4386 - val_weight_output_loss: 1.0524 - val_bag_output_loss: 0.9433 - val_footwear_output_loss: 0.9750 - val_pose_output_loss: 0.9687 - val_emotion_output_loss: 0.9568 - val_gender_output_acc: 0.5000 - val_image_quality_output_acc: 0.5584 - val_age_output_acc: 0.4129 - val_weight_output_acc: 0.6310 - val_bag_output_acc: 0.4784 - val_footwear_output_acc: 0.5573 - val_pose_output_acc: 0.6213 - val_emotion_output_acc: 0.7083\n",
            "Epoch 3/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 7.5621 - gender_output_loss: 0.6220 - image_quality_output_loss: 0.9835 - age_output_loss: 1.4121 - weight_output_loss: 0.9718 - bag_output_loss: 0.8920 - footwear_output_loss: 0.9064 - pose_output_loss: 0.8700 - emotion_output_loss: 0.9043 - gender_output_acc: 0.6492 - image_quality_output_acc: 0.5506 - age_output_acc: 0.3901 - weight_output_acc: 0.6358 - bag_output_acc: 0.5716 - footwear_output_acc: 0.5816 - pose_output_acc: 0.6189 - emotion_output_acc: 0.7127 - val_loss: 7.5317 - val_gender_output_loss: 0.6487 - val_image_quality_output_loss: 0.9669 - val_age_output_loss: 1.3954 - val_weight_output_loss: 0.9740 - val_bag_output_loss: 0.8948 - val_footwear_output_loss: 0.8896 - val_pose_output_loss: 0.8360 - val_emotion_output_loss: 0.9264 - val_gender_output_acc: 0.6109 - val_image_quality_output_acc: 0.5599 - val_age_output_acc: 0.4129 - val_weight_output_acc: 0.6310 - val_bag_output_acc: 0.6016 - val_footwear_output_acc: 0.5949 - val_pose_output_acc: 0.6276 - val_emotion_output_acc: 0.7083\n",
            "Learning rate:  0.01\n",
            "Epoch 4/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 7.4305 - gender_output_loss: 0.6048 - image_quality_output_loss: 0.9800 - age_output_loss: 1.4059 - weight_output_loss: 0.9657 - bag_output_loss: 0.8793 - footwear_output_loss: 0.8927 - pose_output_loss: 0.8056 - emotion_output_loss: 0.8966 - gender_output_acc: 0.6696 - image_quality_output_acc: 0.5505 - age_output_acc: 0.3941 - weight_output_acc: 0.6356 - bag_output_acc: 0.5864 - footwear_output_acc: 0.5907 - pose_output_acc: 0.6499 - emotion_output_acc: 0.7127 - val_loss: 7.6503 - val_gender_output_loss: 0.6324 - val_image_quality_output_loss: 0.9825 - val_age_output_loss: 1.4104 - val_weight_output_loss: 0.9827 - val_bag_output_loss: 0.9245 - val_footwear_output_loss: 0.9280 - val_pose_output_loss: 0.8581 - val_emotion_output_loss: 0.9316 - val_gender_output_acc: 0.6302 - val_image_quality_output_acc: 0.5353 - val_age_output_acc: 0.4122 - val_weight_output_acc: 0.6321 - val_bag_output_acc: 0.5216 - val_footwear_output_acc: 0.5863 - val_pose_output_acc: 0.6514 - val_emotion_output_acc: 0.7080\n",
            "Epoch 5/100\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 7.5621 - gender_output_loss: 0.6220 - image_quality_output_loss: 0.9835 - age_output_loss: 1.4121 - weight_output_loss: 0.9718 - bag_output_loss: 0.8920 - footwear_output_loss: 0.9064 - pose_output_loss: 0.8700 - emotion_output_loss: 0.9043 - gender_output_acc: 0.6492 - image_quality_output_acc: 0.5506 - age_output_acc: 0.3901 - weight_output_acc: 0.6358 - bag_output_acc: 0.5716 - footwear_output_acc: 0.5816 - pose_output_acc: 0.6189 - emotion_output_acc: 0.7127 - val_loss: 7.5317 - val_gender_output_loss: 0.6487 - val_image_quality_output_loss: 0.9669 - val_age_output_loss: 1.3954 - val_weight_output_loss: 0.9740 - val_bag_output_loss: 0.8948 - val_footwear_output_loss: 0.8896 - val_pose_output_loss: 0.8360 - val_emotion_output_loss: 0.9264 - val_gender_output_acc: 0.6109 - val_image_quality_output_acc: 0.5599 - val_age_output_acc: 0.4129 - val_weight_output_acc: 0.6310 - val_bag_output_acc: 0.6016 - val_footwear_output_acc: 0.5949 - val_pose_output_acc: 0.6276 - val_emotion_output_acc: 0.7083\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.01.\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 7.3018 - gender_output_loss: 0.5887 - image_quality_output_loss: 0.9793 - age_output_loss: 1.3971 - weight_output_loss: 0.9598 - bag_output_loss: 0.8732 - footwear_output_loss: 0.8781 - pose_output_loss: 0.7374 - emotion_output_loss: 0.8883 - gender_output_acc: 0.6850 - image_quality_output_acc: 0.5496 - age_output_acc: 0.3963 - weight_output_acc: 0.6367 - bag_output_acc: 0.5897 - footwear_output_acc: 0.5980 - pose_output_acc: 0.6783 - emotion_output_acc: 0.7122 - val_loss: 7.8488 - val_gender_output_loss: 0.6536 - val_image_quality_output_loss: 0.9680 - val_age_output_loss: 1.4395 - val_weight_output_loss: 1.0037 - val_bag_output_loss: 0.9206 - val_footwear_output_loss: 0.9295 - val_pose_output_loss: 0.9931 - val_emotion_output_loss: 0.9407 - val_gender_output_acc: 0.6228 - val_image_quality_output_acc: 0.5588 - val_age_output_acc: 0.4122 - val_weight_output_acc: 0.6310 - val_bag_output_acc: 0.5532 - val_footwear_output_acc: 0.5614 - val_pose_output_acc: 0.5673 - val_emotion_output_acc: 0.7083\n",
            "Epoch 6/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.01.\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 7.1837 - gender_output_loss: 0.5492 - image_quality_output_loss: 0.9768 - age_output_loss: 1.3882 - weight_output_loss: 0.9552 - bag_output_loss: 0.8631 - footwear_output_loss: 0.8737 - pose_output_loss: 0.6959 - emotion_output_loss: 0.8818 - gender_output_acc: 0.7164 - image_quality_output_acc: 0.5514 - age_output_acc: 0.3990 - weight_output_acc: 0.6386 - bag_output_acc: 0.6039 - footwear_output_acc: 0.5964 - pose_output_acc: 0.7024 - emotion_output_acc: 0.7120 - val_loss: 7.6500 - val_gender_output_loss: 0.8221 - val_image_quality_output_loss: 0.9866 - val_age_output_loss: 1.3864 - val_weight_output_loss: 0.9791 - val_bag_output_loss: 0.9288 - val_footwear_output_loss: 0.8968 - val_pose_output_loss: 0.7423 - val_emotion_output_loss: 0.9078 - val_gender_output_acc: 0.5945 - val_image_quality_output_acc: 0.5603 - val_age_output_acc: 0.4182 - val_weight_output_acc: 0.6287 - val_bag_output_acc: 0.5126 - val_footwear_output_acc: 0.5733 - val_pose_output_acc: 0.6949 - val_emotion_output_acc: 0.7080\n",
            "Epoch 7/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.01.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 7.0872 - gender_output_loss: 0.5189 - image_quality_output_loss: 0.9754 - age_output_loss: 1.3863 - weight_output_loss: 0.9516 - bag_output_loss: 0.8569 - footwear_output_loss: 0.8611 - pose_output_loss: 0.6591 - emotion_output_loss: 0.8780 - gender_output_acc: 0.7414 - image_quality_output_acc: 0.5520 - age_output_acc: 0.3952 - weight_output_acc: 0.6391 - bag_output_acc: 0.6100 - footwear_output_acc: 0.6049 - pose_output_acc: 0.7240 - emotion_output_acc: 0.7123Learning rate:  0.01\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 7.0870 - gender_output_loss: 0.5187 - image_quality_output_loss: 0.9753 - age_output_loss: 1.3863 - weight_output_loss: 0.9515 - bag_output_loss: 0.8568 - footwear_output_loss: 0.8616 - pose_output_loss: 0.6592 - emotion_output_loss: 0.8776 - gender_output_acc: 0.7414 - image_quality_output_acc: 0.5521 - age_output_acc: 0.3952 - weight_output_acc: 0.6392 - bag_output_acc: 0.6101 - footwear_output_acc: 0.6047 - pose_output_acc: 0.7239 - emotion_output_acc: 0.7125 - val_loss: 7.1543 - val_gender_output_loss: 0.5295 - val_image_quality_output_loss: 0.9686 - val_age_output_loss: 1.3771 - val_weight_output_loss: 0.9851 - val_bag_output_loss: 0.8457 - val_footwear_output_loss: 0.8557 - val_pose_output_loss: 0.6900 - val_emotion_output_loss: 0.9028 - val_gender_output_acc: 0.7340 - val_image_quality_output_acc: 0.5577 - val_age_output_acc: 0.4230 - val_weight_output_acc: 0.6310 - val_bag_output_acc: 0.6224 - val_footwear_output_acc: 0.6086 - val_pose_output_acc: 0.7087 - val_emotion_output_acc: 0.7080\n",
            "Epoch 8/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 6.9852 - gender_output_loss: 0.4872 - image_quality_output_loss: 0.9711 - age_output_loss: 1.3790 - weight_output_loss: 0.9454 - bag_output_loss: 0.8445 - footwear_output_loss: 0.8580 - pose_output_loss: 0.6254 - emotion_output_loss: 0.8745 - gender_output_acc: 0.7624 - image_quality_output_acc: 0.5507 - age_output_acc: 0.3970 - weight_output_acc: 0.6381 - bag_output_acc: 0.6203 - footwear_output_acc: 0.6060 - pose_output_acc: 0.7423 - emotion_output_acc: 0.7120 - val_loss: 7.3736 - val_gender_output_loss: 0.5600 - val_image_quality_output_loss: 0.9650 - val_age_output_loss: 1.3704 - val_weight_output_loss: 0.9704 - val_bag_output_loss: 0.8546 - val_footwear_output_loss: 0.8681 - val_pose_output_loss: 0.8646 - val_emotion_output_loss: 0.9204 - val_gender_output_acc: 0.7173 - val_image_quality_output_acc: 0.5592 - val_age_output_acc: 0.4103 - val_weight_output_acc: 0.6332 - val_bag_output_acc: 0.6075 - val_footwear_output_acc: 0.6045 - val_pose_output_acc: 0.6124 - val_emotion_output_acc: 0.7083\n",
            "Epoch 9/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.01.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 6.9265 - gender_output_loss: 0.4682 - image_quality_output_loss: 0.9692 - age_output_loss: 1.3756 - weight_output_loss: 0.9404 - bag_output_loss: 0.8399 - footwear_output_loss: 0.8510 - pose_output_loss: 0.6101 - emotion_output_loss: 0.8721 - gender_output_acc: 0.7767 - image_quality_output_acc: 0.5530 - age_output_acc: 0.3999 - weight_output_acc: 0.6378 - bag_output_acc: 0.6246 - footwear_output_acc: 0.6134 - pose_output_acc: 0.7484 - emotion_output_acc: 0.7116Epoch 9/100\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 6.9262 - gender_output_loss: 0.4687 - image_quality_output_loss: 0.9690 - age_output_loss: 1.3754 - weight_output_loss: 0.9402 - bag_output_loss: 0.8403 - footwear_output_loss: 0.8513 - pose_output_loss: 0.6099 - emotion_output_loss: 0.8714 - gender_output_acc: 0.7765 - image_quality_output_acc: 0.5531 - age_output_acc: 0.4002 - weight_output_acc: 0.6379 - bag_output_acc: 0.6245 - footwear_output_acc: 0.6134 - pose_output_acc: 0.7482 - emotion_output_acc: 0.7119 - val_loss: 7.3715 - val_gender_output_loss: 0.7476 - val_image_quality_output_loss: 0.9762 - val_age_output_loss: 1.3812 - val_weight_output_loss: 0.9714 - val_bag_output_loss: 0.8695 - val_footwear_output_loss: 0.8696 - val_pose_output_loss: 0.6407 - val_emotion_output_loss: 0.9154 - val_gender_output_acc: 0.6503 - val_image_quality_output_acc: 0.5569 - val_age_output_acc: 0.4118 - val_weight_output_acc: 0.6254 - val_bag_output_acc: 0.5967 - val_footwear_output_acc: 0.6097 - val_pose_output_acc: 0.7299 - val_emotion_output_acc: 0.7083\n",
            "Epoch 10/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 6.8552 - gender_output_loss: 0.4524 - image_quality_output_loss: 0.9658 - age_output_loss: 1.3731 - weight_output_loss: 0.9351 - bag_output_loss: 0.8290 - footwear_output_loss: 0.8404 - pose_output_loss: 0.5900 - emotion_output_loss: 0.8694 - gender_output_acc: 0.7883 - image_quality_output_acc: 0.5485 - age_output_acc: 0.4041 - weight_output_acc: 0.6368 - bag_output_acc: 0.6298 - footwear_output_acc: 0.6156 - pose_output_acc: 0.7543 - emotion_output_acc: 0.7116 - val_loss: 7.1872 - val_gender_output_loss: 0.5059 - val_image_quality_output_loss: 0.9735 - val_age_output_loss: 1.3639 - val_weight_output_loss: 0.9710 - val_bag_output_loss: 0.9740 - val_footwear_output_loss: 0.8754 - val_pose_output_loss: 0.6234 - val_emotion_output_loss: 0.9002 - val_gender_output_acc: 0.7541 - val_image_quality_output_acc: 0.5480 - val_age_output_acc: 0.4055 - val_weight_output_acc: 0.6187 - val_bag_output_acc: 0.5149 - val_footwear_output_acc: 0.5993 - val_pose_output_acc: 0.7519 - val_emotion_output_acc: 0.7068\n",
            "Epoch 11/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 10/100\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 6.7838 - gender_output_loss: 0.4325 - image_quality_output_loss: 0.9636 - age_output_loss: 1.3645 - weight_output_loss: 0.9286 - bag_output_loss: 0.8227 - footwear_output_loss: 0.8371 - pose_output_loss: 0.5684 - emotion_output_loss: 0.8663 - gender_output_acc: 0.7938 - image_quality_output_acc: 0.5520 - age_output_acc: 0.4038 - weight_output_acc: 0.6389 - bag_output_acc: 0.6374 - footwear_output_acc: 0.6204 - pose_output_acc: 0.7671 - emotion_output_acc: 0.7119 - val_loss: 7.1080 - val_gender_output_loss: 0.4443 - val_image_quality_output_loss: 1.0212 - val_age_output_loss: 1.3710 - val_weight_output_loss: 0.9785 - val_bag_output_loss: 0.8396 - val_footwear_output_loss: 0.8548 - val_pose_output_loss: 0.6794 - val_emotion_output_loss: 0.9192 - val_gender_output_acc: 0.7928 - val_image_quality_output_acc: 0.5402 - val_age_output_acc: 0.4066 - val_weight_output_acc: 0.6224 - val_bag_output_acc: 0.6202 - val_footwear_output_acc: 0.6109 - val_pose_output_acc: 0.7210 - val_emotion_output_acc: 0.7080\n",
            "Epoch 12/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 40s 117ms/step - loss: 6.7253 - gender_output_loss: 0.4208 - image_quality_output_loss: 0.9584 - age_output_loss: 1.3635 - weight_output_loss: 0.9213 - bag_output_loss: 0.8157 - footwear_output_loss: 0.8264 - pose_output_loss: 0.5570 - emotion_output_loss: 0.8622 - gender_output_acc: 0.8052 - image_quality_output_acc: 0.5524 - age_output_acc: 0.4069 - weight_output_acc: 0.6403 - bag_output_acc: 0.6370 - footwear_output_acc: 0.6262 - pose_output_acc: 0.7704 - emotion_output_acc: 0.7123 - val_loss: 7.0139 - val_gender_output_loss: 0.4806 - val_image_quality_output_loss: 0.9518 - val_age_output_loss: 1.3671 - val_weight_output_loss: 0.9649 - val_bag_output_loss: 0.9285 - val_footwear_output_loss: 0.8396 - val_pose_output_loss: 0.5856 - val_emotion_output_loss: 0.8957 - val_gender_output_acc: 0.7753 - val_image_quality_output_acc: 0.5588 - val_age_output_acc: 0.4062 - val_weight_output_acc: 0.6261 - val_bag_output_acc: 0.5580 - val_footwear_output_acc: 0.6190 - val_pose_output_acc: 0.7671 - val_emotion_output_acc: 0.7050\n",
            "Epoch 13/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 6.6566 - gender_output_loss: 0.4036 - image_quality_output_loss: 0.9533 - age_output_loss: 1.3563 - weight_output_loss: 0.9210 - bag_output_loss: 0.8065 - footwear_output_loss: 0.8185 - pose_output_loss: 0.5365 - emotion_output_loss: 0.8610 - gender_output_acc: 0.8143 - image_quality_output_acc: 0.5523 - age_output_acc: 0.4098 - weight_output_acc: 0.6397 - bag_output_acc: 0.6454 - footwear_output_acc: 0.6357 - pose_output_acc: 0.7803 - emotion_output_acc: 0.7122 - val_loss: 7.1122 - val_gender_output_loss: 0.4896 - val_image_quality_output_loss: 0.9556 - val_age_output_loss: 1.3607 - val_weight_output_loss: 1.0044 - val_bag_output_loss: 0.8364 - val_footwear_output_loss: 0.9288 - val_pose_output_loss: 0.6308 - val_emotion_output_loss: 0.9060 - val_gender_output_acc: 0.7649 - val_image_quality_output_acc: 0.5443 - val_age_output_acc: 0.4208 - val_weight_output_acc: 0.5956 - val_bag_output_acc: 0.6298 - val_footwear_output_acc: 0.5353 - val_pose_output_acc: 0.7295 - val_emotion_output_acc: 0.7031\n",
            "Epoch 14/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 6.5932 - gender_output_loss: 0.3932 - image_quality_output_loss: 0.9476 - age_output_loss: 1.3480 - weight_output_loss: 0.9117 - bag_output_loss: 0.7951 - footwear_output_loss: 0.8127 - pose_output_loss: 0.5264 - emotion_output_loss: 0.8585 - gender_output_acc: 0.8222 - image_quality_output_acc: 0.5535 - age_output_acc: 0.4118 - weight_output_acc: 0.6437 - bag_output_acc: 0.6551 - footwear_output_acc: 0.6344 - pose_output_acc: 0.7842 - emotion_output_acc: 0.7119 - val_loss: 6.9954 - val_gender_output_loss: 0.5017 - val_image_quality_output_loss: 0.9736 - val_age_output_loss: 1.3612 - val_weight_output_loss: 0.9663 - val_bag_output_loss: 0.8287 - val_footwear_output_loss: 0.8791 - val_pose_output_loss: 0.5728 - val_emotion_output_loss: 0.9120 - val_gender_output_acc: 0.7634 - val_image_quality_output_acc: 0.5469 - val_age_output_acc: 0.4193 - val_weight_output_acc: 0.6347 - val_bag_output_acc: 0.6272 - val_footwear_output_acc: 0.5926 - val_pose_output_acc: 0.7653 - val_emotion_output_acc: 0.7020\n",
            "Epoch 15/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 6.5440 - gender_output_loss: 0.3833 - image_quality_output_loss: 0.9461 - age_output_loss: 1.3403 - weight_output_loss: 0.9101 - bag_output_loss: 0.7922 - footwear_output_loss: 0.8066 - pose_output_loss: 0.5131 - emotion_output_loss: 0.8524 - gender_output_acc: 0.8232 - image_quality_output_acc: 0.5524 - age_output_acc: 0.4121 - weight_output_acc: 0.6417 - bag_output_acc: 0.6546 - footwear_output_acc: 0.6344 - pose_output_acc: 0.7912 - emotion_output_acc: 0.7126 - val_loss: 7.2484 - val_gender_output_loss: 0.5615 - val_image_quality_output_loss: 1.0521 - val_age_output_loss: 1.4158 - val_weight_output_loss: 0.9712 - val_bag_output_loss: 0.8473 - val_footwear_output_loss: 0.8860 - val_pose_output_loss: 0.5993 - val_emotion_output_loss: 0.9151 - val_gender_output_acc: 0.7563 - val_image_quality_output_acc: 0.5033 - val_age_output_acc: 0.3713 - val_weight_output_acc: 0.6291 - val_bag_output_acc: 0.6217 - val_footwear_output_acc: 0.5915 - val_pose_output_acc: 0.7626 - val_emotion_output_acc: 0.7005\n",
            "Epoch 15/100\n",
            "Learning rate:  0.01\n",
            "Epoch 16/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.01.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 6.5029 - gender_output_loss: 0.3710 - image_quality_output_loss: 0.9363 - age_output_loss: 1.3428 - weight_output_loss: 0.9084 - bag_output_loss: 0.7867 - footwear_output_loss: 0.8032 - pose_output_loss: 0.5021 - emotion_output_loss: 0.8522 - gender_output_acc: 0.8304 - image_quality_output_acc: 0.5582 - age_output_acc: 0.4173 - weight_output_acc: 0.6415 - bag_output_acc: 0.6557 - footwear_output_acc: 0.6428 - pose_output_acc: 0.7975 - emotion_output_acc: 0.7119\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 6.5054 - gender_output_loss: 0.3715 - image_quality_output_loss: 0.9366 - age_output_loss: 1.3427 - weight_output_loss: 0.9088 - bag_output_loss: 0.7872 - footwear_output_loss: 0.8038 - pose_output_loss: 0.5023 - emotion_output_loss: 0.8524 - gender_output_acc: 0.8299 - image_quality_output_acc: 0.5578 - age_output_acc: 0.4171 - weight_output_acc: 0.6413 - bag_output_acc: 0.6552 - footwear_output_acc: 0.6421 - pose_output_acc: 0.7974 - emotion_output_acc: 0.7118 - val_loss: 7.2926 - val_gender_output_loss: 0.4640 - val_image_quality_output_loss: 0.9772 - val_age_output_loss: 1.5416 - val_weight_output_loss: 1.0567 - val_bag_output_loss: 0.8660 - val_footwear_output_loss: 0.8505 - val_pose_output_loss: 0.6287 - val_emotion_output_loss: 0.9080 - val_gender_output_acc: 0.7965 - val_image_quality_output_acc: 0.5350 - val_age_output_acc: 0.3185 - val_weight_output_acc: 0.5863 - val_bag_output_acc: 0.6205 - val_footwear_output_acc: 0.6142 - val_pose_output_acc: 0.7411 - val_emotion_output_acc: 0.7080\n",
            "Epoch 17/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 6.4196 - gender_output_loss: 0.3605 - image_quality_output_loss: 0.9305 - age_output_loss: 1.3308 - weight_output_loss: 0.8904 - bag_output_loss: 0.7787 - footwear_output_loss: 0.7913 - pose_output_loss: 0.4858 - emotion_output_loss: 0.8516 - gender_output_acc: 0.8398 - image_quality_output_acc: 0.5614 - age_output_acc: 0.4180 - weight_output_acc: 0.6477 - bag_output_acc: 0.6661 - footwear_output_acc: 0.6439 - pose_output_acc: 0.8025 - emotion_output_acc: 0.7111 - val_loss: 7.0017 - val_gender_output_loss: 0.4387 - val_image_quality_output_loss: 1.0036 - val_age_output_loss: 1.3980 - val_weight_output_loss: 0.9793 - val_bag_output_loss: 0.8277 - val_footwear_output_loss: 0.8434 - val_pose_output_loss: 0.5978 - val_emotion_output_loss: 0.9132 - val_gender_output_acc: 0.7995 - val_image_quality_output_acc: 0.5205 - val_age_output_acc: 0.3951 - val_weight_output_acc: 0.6235 - val_bag_output_acc: 0.6317 - val_footwear_output_acc: 0.6257 - val_pose_output_acc: 0.7526 - val_emotion_output_acc: 0.7072\n",
            "Epoch 18/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.01.\n",
            "Learning rate:  0.01\n",
            "339/339 [==============================] - 40s 117ms/step - loss: 6.3698 - gender_output_loss: 0.3596 - image_quality_output_loss: 0.9315 - age_output_loss: 1.3209 - weight_output_loss: 0.8833 - bag_output_loss: 0.7693 - footwear_output_loss: 0.7900 - pose_output_loss: 0.4755 - emotion_output_loss: 0.8398 - gender_output_acc: 0.8385 - image_quality_output_acc: 0.5593 - age_output_acc: 0.4177 - weight_output_acc: 0.6518 - bag_output_acc: 0.6715 - footwear_output_acc: 0.6431 - pose_output_acc: 0.8101 - emotion_output_acc: 0.7122 - val_loss: 6.7251 - val_gender_output_loss: 0.4050 - val_image_quality_output_loss: 0.9551 - val_age_output_loss: 1.3539 - val_weight_output_loss: 0.9581 - val_bag_output_loss: 0.8116 - val_footwear_output_loss: 0.8278 - val_pose_output_loss: 0.5074 - val_emotion_output_loss: 0.9061 - val_gender_output_acc: 0.8140 - val_image_quality_output_acc: 0.5644 - val_age_output_acc: 0.4025 - val_weight_output_acc: 0.6283 - val_bag_output_acc: 0.6518 - val_footwear_output_acc: 0.6231 - val_pose_output_acc: 0.8054 - val_emotion_output_acc: 0.7031\n",
            "Epoch 19/100\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 6.3141 - gender_output_loss: 0.3422 - image_quality_output_loss: 0.9218 - age_output_loss: 1.3158 - weight_output_loss: 0.8777 - bag_output_loss: 0.7633 - footwear_output_loss: 0.7845 - pose_output_loss: 0.4685 - emotion_output_loss: 0.8402 - gender_output_acc: 0.8461 - image_quality_output_acc: 0.5667 - age_output_acc: 0.4291 - weight_output_acc: 0.6520 - bag_output_acc: 0.6680 - footwear_output_acc: 0.6485 - pose_output_acc: 0.8155 - emotion_output_acc: 0.7113 - val_loss: 6.8800 - val_gender_output_loss: 0.4205 - val_image_quality_output_loss: 0.9488 - val_age_output_loss: 1.3877 - val_weight_output_loss: 0.9937 - val_bag_output_loss: 0.8323 - val_footwear_output_loss: 0.8425 - val_pose_output_loss: 0.5426 - val_emotion_output_loss: 0.9119 - val_gender_output_acc: 0.8073 - val_image_quality_output_acc: 0.5391 - val_age_output_acc: 0.3966 - val_weight_output_acc: 0.5956 - val_bag_output_acc: 0.6451 - val_footwear_output_acc: 0.6138 - val_pose_output_acc: 0.7868 - val_emotion_output_acc: 0.7020\n",
            "Epoch 20/100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.01.\n",
            "Learning rate:  0.01\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 6.2685 - gender_output_loss: 0.3378 - image_quality_output_loss: 0.9161 - age_output_loss: 1.3100 - weight_output_loss: 0.8753 - bag_output_loss: 0.7596 - footwear_output_loss: 0.7752 - pose_output_loss: 0.4599 - emotion_output_loss: 0.8344 - gender_output_acc: 0.8543 - image_quality_output_acc: 0.5649 - age_output_acc: 0.4274 - weight_output_acc: 0.6518 - bag_output_acc: 0.6795 - footwear_output_acc: 0.6504 - pose_output_acc: 0.8174 - emotion_output_acc: 0.7133 - val_loss: 6.9257 - val_gender_output_loss: 0.4275 - val_image_quality_output_loss: 0.9549 - val_age_output_loss: 1.3715 - val_weight_output_loss: 0.9772 - val_bag_output_loss: 0.8588 - val_footwear_output_loss: 0.8540 - val_pose_output_loss: 0.5535 - val_emotion_output_loss: 0.9284 - val_gender_output_acc: 0.8155 - val_image_quality_output_acc: 0.5517 - val_age_output_acc: 0.4118 - val_weight_output_acc: 0.6313 - val_bag_output_acc: 0.6254 - val_footwear_output_acc: 0.6176 - val_pose_output_acc: 0.7816 - val_emotion_output_acc: 0.6942\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Learning rate:  Learning rate:  0.01\n",
            "0.01\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 6.2050 - gender_output_loss: 0.3271 - image_quality_output_loss: 0.9091 - age_output_loss: 1.3016 - weight_output_loss: 0.8734 - bag_output_loss: 0.7499 - footwear_output_loss: 0.7660 - pose_output_loss: 0.4411 - emotion_output_loss: 0.8366 - gender_output_acc: 0.8548 - image_quality_output_acc: 0.5691 - age_output_acc: 0.4267 - weight_output_acc: 0.6502 - bag_output_acc: 0.6795 - footwear_output_acc: 0.6543 - pose_output_acc: 0.8284 - emotion_output_acc: 0.7140 - val_loss: 7.0956 - val_gender_output_loss: 0.5034 - val_image_quality_output_loss: 1.0170 - val_age_output_loss: 1.3836 - val_weight_output_loss: 0.9592 - val_bag_output_loss: 0.8800 - val_footwear_output_loss: 0.8731 - val_pose_output_loss: 0.5411 - val_emotion_output_loss: 0.9382 - val_gender_output_acc: 0.7723 - val_image_quality_output_acc: 0.5041 - val_age_output_acc: 0.4036 - val_weight_output_acc: 0.6332 - val_bag_output_acc: 0.6120 - val_footwear_output_acc: 0.6012 - val_pose_output_acc: 0.7846 - val_emotion_output_acc: 0.6894\n",
            "Epoch 22/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.01.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 5.8741 - gender_output_loss: 0.2833 - image_quality_output_loss: 0.8764 - age_output_loss: 1.2578 - weight_output_loss: 0.8324 - bag_output_loss: 0.7073 - footwear_output_loss: 0.7296 - pose_output_loss: 0.3830 - emotion_output_loss: 0.8045 - gender_output_acc: 0.8815 - image_quality_output_acc: 0.5843 - age_output_acc: 0.4550 - weight_output_acc: 0.6631 - bag_output_acc: 0.7046 - footwear_output_acc: 0.6762 - pose_output_acc: 0.8536 - emotion_output_acc: 0.7158 - val_loss: 6.7086 - val_gender_output_loss: 0.3931 - val_image_quality_output_loss: 0.9629 - val_age_output_loss: 1.3545 - val_weight_output_loss: 0.9420 - val_bag_output_loss: 0.8167 - val_footwear_output_loss: 0.8289 - val_pose_output_loss: 0.5069 - val_emotion_output_loss: 0.9036 - val_gender_output_acc: 0.8266 - val_image_quality_output_acc: 0.5450 - val_age_output_acc: 0.4062 - val_weight_output_acc: 0.6339 - val_bag_output_acc: 0.6507 - val_footwear_output_acc: 0.6291 - val_pose_output_acc: 0.7995 - val_emotion_output_acc: 0.7035\n",
            "\n",
            "Epoch 23/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 5.7574 - gender_output_loss: 0.2625 - image_quality_output_loss: 0.8689 - age_output_loss: 1.2393 - weight_output_loss: 0.8153 - bag_output_loss: 0.6975 - footwear_output_loss: 0.7154 - pose_output_loss: 0.3569 - emotion_output_loss: 0.8015 - gender_output_acc: 0.8898 - image_quality_output_acc: 0.5906 - age_output_acc: 0.4649 - weight_output_acc: 0.6678 - bag_output_acc: 0.7082 - footwear_output_acc: 0.6847 - pose_output_acc: 0.8644 - emotion_output_acc: 0.7170 - val_loss: 6.6795 - val_gender_output_loss: 0.3861 - val_image_quality_output_loss: 0.9388 - val_age_output_loss: 1.3567 - val_weight_output_loss: 0.9459 - val_bag_output_loss: 0.8172 - val_footwear_output_loss: 0.8293 - val_pose_output_loss: 0.5012 - val_emotion_output_loss: 0.9042 - val_gender_output_acc: 0.8322 - val_image_quality_output_acc: 0.5584 - val_age_output_acc: 0.4074 - val_weight_output_acc: 0.6339 - val_bag_output_acc: 0.6469 - val_footwear_output_acc: 0.6269 - val_pose_output_acc: 0.8077 - val_emotion_output_acc: 0.7046\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 23/100Epoch 24/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 5.7062 - gender_output_loss: 0.2542 - image_quality_output_loss: 0.8617 - age_output_loss: 1.2322 - weight_output_loss: 0.8124 - bag_output_loss: 0.6903 - footwear_output_loss: 0.7087 - pose_output_loss: 0.3524 - emotion_output_loss: 0.7944 - gender_output_acc: 0.8896 - image_quality_output_acc: 0.5926 - age_output_acc: 0.4729 - weight_output_acc: 0.6697 - bag_output_acc: 0.7124 - footwear_output_acc: 0.6861 - pose_output_acc: 0.8626 - emotion_output_acc: 0.7172 - val_loss: 6.7406 - val_gender_output_loss: 0.3959 - val_image_quality_output_loss: 0.9513 - val_age_output_loss: 1.3617 - val_weight_output_loss: 0.9510 - val_bag_output_loss: 0.8235 - val_footwear_output_loss: 0.8373 - val_pose_output_loss: 0.5106 - val_emotion_output_loss: 0.9094 - val_gender_output_acc: 0.8233 - val_image_quality_output_acc: 0.5476 - val_age_output_acc: 0.3988 - val_weight_output_acc: 0.6317 - val_bag_output_acc: 0.6417 - val_footwear_output_acc: 0.6313 - val_pose_output_acc: 0.8006 - val_emotion_output_acc: 0.7024\n",
            "Epoch 25/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 117ms/step - loss: 5.6490 - gender_output_loss: 0.2490 - image_quality_output_loss: 0.8562 - age_output_loss: 1.2215 - weight_output_loss: 0.8012 - bag_output_loss: 0.6805 - footwear_output_loss: 0.6986 - pose_output_loss: 0.3507 - emotion_output_loss: 0.7914 - gender_output_acc: 0.8948 - image_quality_output_acc: 0.5968 - age_output_acc: 0.4722 - weight_output_acc: 0.6722 - bag_output_acc: 0.7164 - footwear_output_acc: 0.6902 - pose_output_acc: 0.8673 - emotion_output_acc: 0.7176 - val_loss: 6.7465 - val_gender_output_loss: 0.3885 - val_image_quality_output_loss: 0.9695 - val_age_output_loss: 1.3658 - val_weight_output_loss: 0.9496 - val_bag_output_loss: 0.8199 - val_footwear_output_loss: 0.8409 - val_pose_output_loss: 0.5038 - val_emotion_output_loss: 0.9085 - val_gender_output_acc: 0.8292 - val_image_quality_output_acc: 0.5491 - val_age_output_acc: 0.3932 - val_weight_output_acc: 0.6358 - val_bag_output_acc: 0.6492 - val_footwear_output_acc: 0.6339 - val_pose_output_acc: 0.8058 - val_emotion_output_acc: 0.7050\n",
            "Epoch 26/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 5.6104 - gender_output_loss: 0.2466 - image_quality_output_loss: 0.8522 - age_output_loss: 1.2157 - weight_output_loss: 0.7952 - bag_output_loss: 0.6743 - footwear_output_loss: 0.6989 - pose_output_loss: 0.3422 - emotion_output_loss: 0.7854 - gender_output_acc: 0.8966 - image_quality_output_acc: 0.5986 - age_output_acc: 0.4789 - weight_output_acc: 0.6818 - bag_output_acc: 0.7182 - footwear_output_acc: 0.6975 - pose_output_acc: 0.8709 - emotion_output_acc: 0.7163 - val_loss: 6.8163 - val_gender_output_loss: 0.4108 - val_image_quality_output_loss: 0.9778 - val_age_output_loss: 1.3720 - val_weight_output_loss: 0.9605 - val_bag_output_loss: 0.8279 - val_footwear_output_loss: 0.8401 - val_pose_output_loss: 0.5116 - val_emotion_output_loss: 0.9156 - val_gender_output_acc: 0.8263 - val_image_quality_output_acc: 0.5357 - val_age_output_acc: 0.3984 - val_weight_output_acc: 0.6265 - val_bag_output_acc: 0.6447 - val_footwear_output_acc: 0.6276 - val_pose_output_acc: 0.8032 - val_emotion_output_acc: 0.7016\n",
            "Epoch 27/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 5.5910 - gender_output_loss: 0.2457 - image_quality_output_loss: 0.8520 - age_output_loss: 1.2090 - weight_output_loss: 0.7960 - bag_output_loss: 0.6739 - footwear_output_loss: 0.6977 - pose_output_loss: 0.3356 - emotion_output_loss: 0.7810 - gender_output_acc: 0.8951 - image_quality_output_acc: 0.5950 - age_output_acc: 0.4722 - weight_output_acc: 0.6754 - bag_output_acc: 0.7158 - footwear_output_acc: 0.6913 - pose_output_acc: 0.8705 - emotion_output_acc: 0.7186 - val_loss: 6.7867 - val_gender_output_loss: 0.3943 - val_image_quality_output_loss: 0.9550 - val_age_output_loss: 1.3747 - val_weight_output_loss: 0.9552 - val_bag_output_loss: 0.8250 - val_footwear_output_loss: 0.8446 - val_pose_output_loss: 0.5206 - val_emotion_output_loss: 0.9173 - val_gender_output_acc: 0.8281 - val_image_quality_output_acc: 0.5521 - val_age_output_acc: 0.3969 - val_weight_output_acc: 0.6246 - val_bag_output_acc: 0.6469 - val_footwear_output_acc: 0.6347 - val_pose_output_acc: 0.7991 - val_emotion_output_acc: 0.7042\n",
            "Epoch 28/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 5.5484 - gender_output_loss: 0.2322 - image_quality_output_loss: 0.8458 - age_output_loss: 1.2082 - weight_output_loss: 0.7905 - bag_output_loss: 0.6679 - footwear_output_loss: 0.6916 - pose_output_loss: 0.3335 - emotion_output_loss: 0.7788 - gender_output_acc: 0.9039 - image_quality_output_acc: 0.6054 - age_output_acc: 0.4817 - weight_output_acc: 0.6814 - bag_output_acc: 0.7258 - footwear_output_acc: 0.6952 - pose_output_acc: 0.8720 - emotion_output_acc: 0.7199 - val_loss: 6.8268 - val_gender_output_loss: 0.3957 - val_image_quality_output_loss: 0.9852 - val_age_output_loss: 1.3739 - val_weight_output_loss: 0.9605 - val_bag_output_loss: 0.8237 - val_footwear_output_loss: 0.8559 - val_pose_output_loss: 0.5119 - val_emotion_output_loss: 0.9202 - val_gender_output_acc: 0.8289 - val_image_quality_output_acc: 0.5316 - val_age_output_acc: 0.3973 - val_weight_output_acc: 0.6283 - val_bag_output_acc: 0.6488 - val_footwear_output_acc: 0.6235 - val_pose_output_acc: 0.8058 - val_emotion_output_acc: 0.7024\n",
            "Epoch 29/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 28/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 40s 117ms/step - loss: 5.5331 - gender_output_loss: 0.2393 - image_quality_output_loss: 0.8426 - age_output_loss: 1.2080 - weight_output_loss: 0.7906 - bag_output_loss: 0.6672 - footwear_output_loss: 0.6824 - pose_output_loss: 0.3261 - emotion_output_loss: 0.7769 - gender_output_acc: 0.8995 - image_quality_output_acc: 0.6032 - age_output_acc: 0.4756 - weight_output_acc: 0.6792 - bag_output_acc: 0.7201 - footwear_output_acc: 0.7054 - pose_output_acc: 0.8752 - emotion_output_acc: 0.7208 - val_loss: 6.8127 - val_gender_output_loss: 0.4009 - val_image_quality_output_loss: 0.9595 - val_age_output_loss: 1.3807 - val_weight_output_loss: 0.9594 - val_bag_output_loss: 0.8249 - val_footwear_output_loss: 0.8483 - val_pose_output_loss: 0.5202 - val_emotion_output_loss: 0.9187 - val_gender_output_acc: 0.8255 - val_image_quality_output_acc: 0.5517 - val_age_output_acc: 0.3906 - val_weight_output_acc: 0.6239 - val_bag_output_acc: 0.6507 - val_footwear_output_acc: 0.6269 - val_pose_output_acc: 0.7969 - val_emotion_output_acc: 0.7039\n",
            "Epoch 30/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 5.5169 - gender_output_loss: 0.2377 - image_quality_output_loss: 0.8397 - age_output_loss: 1.2024 - weight_output_loss: 0.7840 - bag_output_loss: 0.6630 - footwear_output_loss: 0.6873 - pose_output_loss: 0.3274 - emotion_output_loss: 0.7753 - gender_output_acc: 0.9010 - image_quality_output_acc: 0.6070 - age_output_acc: 0.4783 - weight_output_acc: 0.6798 - bag_output_acc: 0.7265 - footwear_output_acc: 0.6999 - pose_output_acc: 0.8724 - emotion_output_acc: 0.7192 - val_loss: 6.8474 - val_gender_output_loss: 0.4089 - val_image_quality_output_loss: 0.9648 - val_age_output_loss: 1.3852 - val_weight_output_loss: 0.9639 - val_bag_output_loss: 0.8299 - val_footwear_output_loss: 0.8457 - val_pose_output_loss: 0.5272 - val_emotion_output_loss: 0.9219 - val_gender_output_acc: 0.8281 - val_image_quality_output_acc: 0.5443 - val_age_output_acc: 0.3850 - val_weight_output_acc: 0.6228 - val_bag_output_acc: 0.6496 - val_footwear_output_acc: 0.6302 - val_pose_output_acc: 0.7928 - val_emotion_output_acc: 0.7001\n",
            "Epoch 31/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
            "  1/339 [..............................] - ETA: 1:04 - loss: 5.3503 - gender_output_loss: 0.2907 - image_quality_output_loss: 0.8654 - age_output_loss: 1.2014 - weight_output_loss: 0.6802 - bag_output_loss: 0.6147 - footwear_output_loss: 0.7884 - pose_output_loss: 0.1774 - emotion_output_loss: 0.7321 - gender_output_acc: 0.8125 - image_quality_output_acc: 0.5938 - age_output_acc: 0.5000 - weight_output_acc: 0.6875 - bag_output_acc: 0.8438 - footwear_output_acc: 0.5312 - pose_output_acc: 0.9688 - emotion_output_acc: 0.6875Learning rate:  0.001\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 5.4729 - gender_output_loss: 0.2321 - image_quality_output_loss: 0.8399 - age_output_loss: 1.1924 - weight_output_loss: 0.7808 - bag_output_loss: 0.6559 - footwear_output_loss: 0.6796 - pose_output_loss: 0.3217 - emotion_output_loss: 0.7706 - gender_output_acc: 0.9049 - image_quality_output_acc: 0.6070 - age_output_acc: 0.4851 - weight_output_acc: 0.6810 - bag_output_acc: 0.7264 - footwear_output_acc: 0.7068 - pose_output_acc: 0.8747 - emotion_output_acc: 0.7174 - val_loss: 6.8434 - val_gender_output_loss: 0.4026 - val_image_quality_output_loss: 0.9549 - val_age_output_loss: 1.3854 - val_weight_output_loss: 0.9698 - val_bag_output_loss: 0.8325 - val_footwear_output_loss: 0.8506 - val_pose_output_loss: 0.5257 - val_emotion_output_loss: 0.9221 - val_gender_output_acc: 0.8304 - val_image_quality_output_acc: 0.5391 - val_age_output_acc: 0.3862 - val_weight_output_acc: 0.6190 - val_bag_output_acc: 0.6443 - val_footwear_output_acc: 0.6295 - val_pose_output_acc: 0.8025 - val_emotion_output_acc: 0.6912\n",
            "Epoch 32/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 116ms/step - loss: 5.4350 - gender_output_loss: 0.2287 - image_quality_output_loss: 0.8336 - age_output_loss: 1.1907 - weight_output_loss: 0.7709 - bag_output_loss: 0.6504 - footwear_output_loss: 0.6695 - pose_output_loss: 0.3184 - emotion_output_loss: 0.7729 - gender_output_acc: 0.9012 - image_quality_output_acc: 0.6090 - age_output_acc: 0.4876 - weight_output_acc: 0.6869 - bag_output_acc: 0.7307 - footwear_output_acc: 0.7052 - pose_output_acc: 0.8745 - emotion_output_acc: 0.7189 - val_loss: 6.8608 - val_gender_output_loss: 0.4038 - val_image_quality_output_loss: 0.9687 - val_age_output_loss: 1.3833 - val_weight_output_loss: 0.9670 - val_bag_output_loss: 0.8356 - val_footwear_output_loss: 0.8554 - val_pose_output_loss: 0.5235 - val_emotion_output_loss: 0.9235 - val_gender_output_acc: 0.8266 - val_image_quality_output_acc: 0.5465 - val_age_output_acc: 0.3929 - val_weight_output_acc: 0.6209 - val_bag_output_acc: 0.6432 - val_footwear_output_acc: 0.6265 - val_pose_output_acc: 0.8013 - val_emotion_output_acc: 0.6979\n",
            "Epoch 33/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 32/100\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 5.4105 - gender_output_loss: 0.2280 - image_quality_output_loss: 0.8307 - age_output_loss: 1.1873 - weight_output_loss: 0.7732 - bag_output_loss: 0.6469 - footwear_output_loss: 0.6746 - pose_output_loss: 0.3055 - emotion_output_loss: 0.7644 - gender_output_acc: 0.9028 - image_quality_output_acc: 0.6100 - age_output_acc: 0.4923 - weight_output_acc: 0.6845 - bag_output_acc: 0.7338 - footwear_output_acc: 0.7040 - pose_output_acc: 0.8818 - emotion_output_acc: 0.7212 - val_loss: 6.8713 - val_gender_output_loss: 0.4167 - val_image_quality_output_loss: 0.9565 - val_age_output_loss: 1.3863 - val_weight_output_loss: 0.9667 - val_bag_output_loss: 0.8355 - val_footwear_output_loss: 0.8540 - val_pose_output_loss: 0.5290 - val_emotion_output_loss: 0.9267 - val_gender_output_acc: 0.8281 - val_image_quality_output_acc: 0.5502 - val_age_output_acc: 0.3903 - val_weight_output_acc: 0.6202 - val_bag_output_acc: 0.6462 - val_footwear_output_acc: 0.6209 - val_pose_output_acc: 0.8025 - val_emotion_output_acc: 0.6864\n",
            "Epoch 34/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 5.4123 - gender_output_loss: 0.2261 - image_quality_output_loss: 0.8312 - age_output_loss: 1.1815 - weight_output_loss: 0.7714 - bag_output_loss: 0.6503 - footwear_output_loss: 0.6707 - pose_output_loss: 0.3177 - emotion_output_loss: 0.7634 - gender_output_acc: 0.9053 - image_quality_output_acc: 0.6112 - age_output_acc: 0.4899 - weight_output_acc: 0.6861 - bag_output_acc: 0.7318 - footwear_output_acc: 0.7058 - pose_output_acc: 0.8786 - emotion_output_acc: 0.7196 - val_loss: 6.9160 - val_gender_output_loss: 0.4058 - val_image_quality_output_loss: 0.9968 - val_age_output_loss: 1.3905 - val_weight_output_loss: 0.9669 - val_bag_output_loss: 0.8392 - val_footwear_output_loss: 0.8627 - val_pose_output_loss: 0.5251 - val_emotion_output_loss: 0.9292 - val_gender_output_acc: 0.8296 - val_image_quality_output_acc: 0.5279 - val_age_output_acc: 0.3925 - val_weight_output_acc: 0.6228 - val_bag_output_acc: 0.6429 - val_footwear_output_acc: 0.6254 - val_pose_output_acc: 0.7999 - val_emotion_output_acc: 0.7024\n",
            "Epoch 35/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 34/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 5.3751 - gender_output_loss: 0.2267 - image_quality_output_loss: 0.8275 - age_output_loss: 1.1821 - weight_output_loss: 0.7639 - bag_output_loss: 0.6423 - footwear_output_loss: 0.6606 - pose_output_loss: 0.3087 - emotion_output_loss: 0.7632 - gender_output_acc: 0.9074 - image_quality_output_acc: 0.6121 - age_output_acc: 0.4905 - weight_output_acc: 0.6921 - bag_output_acc: 0.7342 - footwear_output_acc: 0.7117 - pose_output_acc: 0.8826 - emotion_output_acc: 0.7220 - val_loss: 6.9129 - val_gender_output_loss: 0.4114 - val_image_quality_output_loss: 0.9645 - val_age_output_loss: 1.3989 - val_weight_output_loss: 0.9713 - val_bag_output_loss: 0.8470 - val_footwear_output_loss: 0.8611 - val_pose_output_loss: 0.5325 - val_emotion_output_loss: 0.9262 - val_gender_output_acc: 0.8259 - val_image_quality_output_acc: 0.5491 - val_age_output_acc: 0.3850 - val_weight_output_acc: 0.6205 - val_bag_output_acc: 0.6391 - val_footwear_output_acc: 0.6246 - val_pose_output_acc: 0.7995 - val_emotion_output_acc: 0.6968\n",
            "Epoch 36/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 115ms/step - loss: 5.3493 - gender_output_loss: 0.2194 - image_quality_output_loss: 0.8211 - age_output_loss: 1.1727 - weight_output_loss: 0.7621 - bag_output_loss: 0.6419 - footwear_output_loss: 0.6675 - pose_output_loss: 0.2981 - emotion_output_loss: 0.7665 - gender_output_acc: 0.9073 - image_quality_output_acc: 0.6190 - age_output_acc: 0.4978 - weight_output_acc: 0.6901 - bag_output_acc: 0.7364 - footwear_output_acc: 0.7092 - pose_output_acc: 0.8862 - emotion_output_acc: 0.7221 - val_loss: 6.9326 - val_gender_output_loss: 0.4058 - val_image_quality_output_loss: 0.9826 - val_age_output_loss: 1.3954 - val_weight_output_loss: 0.9716 - val_bag_output_loss: 0.8447 - val_footwear_output_loss: 0.8646 - val_pose_output_loss: 0.5351 - val_emotion_output_loss: 0.9329 - val_gender_output_acc: 0.8333 - val_image_quality_output_acc: 0.5428 - val_age_output_acc: 0.3925 - val_weight_output_acc: 0.6287 - val_bag_output_acc: 0.6403 - val_footwear_output_acc: 0.6183 - val_pose_output_acc: 0.8006 - val_emotion_output_acc: 0.6927\n",
            "Epoch 37/100\n",
            "\n",
            "Learning rate:  0.001\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 5.3452 - gender_output_loss: 0.2263 - image_quality_output_loss: 0.8228 - age_output_loss: 1.1727 - weight_output_loss: 0.7586 - bag_output_loss: 0.6393 - footwear_output_loss: 0.6605 - pose_output_loss: 0.3056 - emotion_output_loss: 0.7593 - gender_output_acc: 0.9073 - image_quality_output_acc: 0.6166 - age_output_acc: 0.5006 - weight_output_acc: 0.6925 - bag_output_acc: 0.7351 - footwear_output_acc: 0.7142 - pose_output_acc: 0.8822 - emotion_output_acc: 0.7227 - val_loss: 6.9638 - val_gender_output_loss: 0.4150 - val_image_quality_output_loss: 0.9763 - val_age_output_loss: 1.3974 - val_weight_output_loss: 0.9811 - val_bag_output_loss: 0.8495 - val_footwear_output_loss: 0.8711 - val_pose_output_loss: 0.5394 - val_emotion_output_loss: 0.9341 - val_gender_output_acc: 0.8326 - val_image_quality_output_acc: 0.5439 - val_age_output_acc: 0.3917 - val_weight_output_acc: 0.6142 - val_bag_output_acc: 0.6399 - val_footwear_output_acc: 0.6205 - val_pose_output_acc: 0.7939 - val_emotion_output_acc: 0.6860\n",
            "Epoch 38/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 5.3156 - gender_output_loss: 0.2210 - image_quality_output_loss: 0.8237 - age_output_loss: 1.1635 - weight_output_loss: 0.7571 - bag_output_loss: 0.6327 - footwear_output_loss: 0.6617 - pose_output_loss: 0.2993 - emotion_output_loss: 0.7564 - gender_output_acc: 0.9091 - image_quality_output_acc: 0.6114 - age_output_acc: 0.4982 - weight_output_acc: 0.6935 - bag_output_acc: 0.7359 - footwear_output_acc: 0.7113 - pose_output_acc: 0.8826 - emotion_output_acc: 0.7238 - val_loss: 6.9558 - val_gender_output_loss: 0.4101 - val_image_quality_output_loss: 0.9844 - val_age_output_loss: 1.3981 - val_weight_output_loss: 0.9782 - val_bag_output_loss: 0.8460 - val_footwear_output_loss: 0.8697 - val_pose_output_loss: 0.5388 - val_emotion_output_loss: 0.9304 - val_gender_output_acc: 0.8274 - val_image_quality_output_acc: 0.5357 - val_age_output_acc: 0.3969 - val_weight_output_acc: 0.6231 - val_bag_output_acc: 0.6488 - val_footwear_output_acc: 0.6179 - val_pose_output_acc: 0.8017 - val_emotion_output_acc: 0.6875\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 39/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 5.2980 - gender_output_loss: 0.2157 - image_quality_output_loss: 0.8186 - age_output_loss: 1.1599 - weight_output_loss: 0.7579 - bag_output_loss: 0.6353 - footwear_output_loss: 0.6567 - pose_output_loss: 0.3015 - emotion_output_loss: 0.7524 - gender_output_acc: 0.9121 - image_quality_output_acc: 0.6165 - age_output_acc: 0.5079 - weight_output_acc: 0.6904 - bag_output_acc: 0.7400 - footwear_output_acc: 0.7175 - pose_output_acc: 0.8827 - emotion_output_acc: 0.7292 - val_loss: 6.9172 - val_gender_output_loss: 0.4092 - val_image_quality_output_loss: 0.9592 - val_age_output_loss: 1.3986 - val_weight_output_loss: 0.9748 - val_bag_output_loss: 0.8451 - val_footwear_output_loss: 0.8639 - val_pose_output_loss: 0.5345 - val_emotion_output_loss: 0.9319 - val_gender_output_acc: 0.8322 - val_image_quality_output_acc: 0.5398 - val_age_output_acc: 0.3966 - val_weight_output_acc: 0.6168 - val_bag_output_acc: 0.6440 - val_footwear_output_acc: 0.6220 - val_pose_output_acc: 0.7991 - val_emotion_output_acc: 0.6920\n",
            "Epoch 39/100\n",
            "Learning rate:  0.001\n",
            "Epoch 40/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 5.2724 - gender_output_loss: 0.2160 - image_quality_output_loss: 0.8133 - age_output_loss: 1.1571 - weight_output_loss: 0.7500 - bag_output_loss: 0.6307 - footwear_output_loss: 0.6553 - pose_output_loss: 0.2989 - emotion_output_loss: 0.7513 - gender_output_acc: 0.9126 - image_quality_output_acc: 0.6194 - age_output_acc: 0.5061 - weight_output_acc: 0.6935 - bag_output_acc: 0.7340 - footwear_output_acc: 0.7142 - pose_output_acc: 0.8843 - emotion_output_acc: 0.7233 - val_loss: 6.9564 - val_gender_output_loss: 0.4152 - val_image_quality_output_loss: 0.9637 - val_age_output_loss: 1.3956 - val_weight_output_loss: 0.9782 - val_bag_output_loss: 0.8534 - val_footwear_output_loss: 0.8720 - val_pose_output_loss: 0.5417 - val_emotion_output_loss: 0.9366 - val_gender_output_acc: 0.8300 - val_image_quality_output_acc: 0.5450 - val_age_output_acc: 0.3932 - val_weight_output_acc: 0.6198 - val_bag_output_acc: 0.6455 - val_footwear_output_acc: 0.6097 - val_pose_output_acc: 0.7980 - val_emotion_output_acc: 0.6912\n",
            "Epoch 41/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 5.2564 - gender_output_loss: 0.2147 - image_quality_output_loss: 0.8118 - age_output_loss: 1.1568 - weight_output_loss: 0.7499 - bag_output_loss: 0.6287 - footwear_output_loss: 0.6482 - pose_output_loss: 0.2930 - emotion_output_loss: 0.7533 - gender_output_acc: 0.9100 - image_quality_output_acc: 0.6198 - age_output_acc: 0.5028 - weight_output_acc: 0.6975 - bag_output_acc: 0.7409 - footwear_output_acc: 0.7237 - pose_output_acc: 0.8835 - emotion_output_acc: 0.7254\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 41/100\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 5.2569 - gender_output_loss: 0.2149 - image_quality_output_loss: 0.8118 - age_output_loss: 1.1571 - weight_output_loss: 0.7501 - bag_output_loss: 0.6291 - footwear_output_loss: 0.6477 - pose_output_loss: 0.2929 - emotion_output_loss: 0.7533 - gender_output_acc: 0.9099 - image_quality_output_acc: 0.6198 - age_output_acc: 0.5028 - weight_output_acc: 0.6974 - bag_output_acc: 0.7405 - footwear_output_acc: 0.7239 - pose_output_acc: 0.8836 - emotion_output_acc: 0.7255 - val_loss: 7.0443 - val_gender_output_loss: 0.4348 - val_image_quality_output_loss: 0.9863 - val_age_output_loss: 1.4078 - val_weight_output_loss: 0.9918 - val_bag_output_loss: 0.8553 - val_footwear_output_loss: 0.8729 - val_pose_output_loss: 0.5530 - val_emotion_output_loss: 0.9423 - val_gender_output_acc: 0.8263 - val_image_quality_output_acc: 0.5279 - val_age_output_acc: 0.3925 - val_weight_output_acc: 0.6086 - val_bag_output_acc: 0.6436 - val_footwear_output_acc: 0.6109 - val_pose_output_acc: 0.7943 - val_emotion_output_acc: 0.6912\n",
            "Epoch 42/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 5.2245 - gender_output_loss: 0.2017 - image_quality_output_loss: 0.8145 - age_output_loss: 1.1499 - weight_output_loss: 0.7510 - bag_output_loss: 0.6268 - footwear_output_loss: 0.6453 - pose_output_loss: 0.2874 - emotion_output_loss: 0.7478 - gender_output_acc: 0.9176 - image_quality_output_acc: 0.6205 - age_output_acc: 0.5097 - weight_output_acc: 0.6950 - bag_output_acc: 0.7396 - footwear_output_acc: 0.7218 - pose_output_acc: 0.8898 - emotion_output_acc: 0.7235 - val_loss: 7.0009 - val_gender_output_loss: 0.4374 - val_image_quality_output_loss: 0.9765 - val_age_output_loss: 1.3997 - val_weight_output_loss: 0.9822 - val_bag_output_loss: 0.8609 - val_footwear_output_loss: 0.8701 - val_pose_output_loss: 0.5348 - val_emotion_output_loss: 0.9392 - val_gender_output_acc: 0.8259 - val_image_quality_output_acc: 0.5346 - val_age_output_acc: 0.3850 - val_weight_output_acc: 0.6198 - val_bag_output_acc: 0.6369 - val_footwear_output_acc: 0.6127 - val_pose_output_acc: 0.8032 - val_emotion_output_acc: 0.6972\n",
            "Epoch 42/100\n",
            "Learning rate:  0.001\n",
            "Epoch 43/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 5.2137 - gender_output_loss: 0.2113 - image_quality_output_loss: 0.8110 - age_output_loss: 1.1471 - weight_output_loss: 0.7381 - bag_output_loss: 0.6256 - footwear_output_loss: 0.6470 - pose_output_loss: 0.2876 - emotion_output_loss: 0.7460 - gender_output_acc: 0.9134 - image_quality_output_acc: 0.6270 - age_output_acc: 0.5092 - weight_output_acc: 0.7015 - bag_output_acc: 0.7431 - footwear_output_acc: 0.7199 - pose_output_acc: 0.8891 - emotion_output_acc: 0.7241 - val_loss: 7.0420 - val_gender_output_loss: 0.4336 - val_image_quality_output_loss: 0.9966 - val_age_output_loss: 1.4067 - val_weight_output_loss: 0.9884 - val_bag_output_loss: 0.8600 - val_footwear_output_loss: 0.8700 - val_pose_output_loss: 0.5440 - val_emotion_output_loss: 0.9426 - val_gender_output_acc: 0.8259 - val_image_quality_output_acc: 0.5272 - val_age_output_acc: 0.3947 - val_weight_output_acc: 0.6164 - val_bag_output_acc: 0.6373 - val_footwear_output_acc: 0.6235 - val_pose_output_acc: 0.7984 - val_emotion_output_acc: 0.6920\n",
            "Epoch 44/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 5.2001 - gender_output_loss: 0.2095 - image_quality_output_loss: 0.8069 - age_output_loss: 1.1371 - weight_output_loss: 0.7406 - bag_output_loss: 0.6171 - footwear_output_loss: 0.6512 - pose_output_loss: 0.2974 - emotion_output_loss: 0.7403 - gender_output_acc: 0.9148 - image_quality_output_acc: 0.6204 - age_output_acc: 0.5127 - weight_output_acc: 0.6977 - bag_output_acc: 0.7476 - footwear_output_acc: 0.7157 - pose_output_acc: 0.8850 - emotion_output_acc: 0.7270\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 5.2012 - gender_output_loss: 0.2094 - image_quality_output_loss: 0.8077 - age_output_loss: 1.1364 - weight_output_loss: 0.7408 - bag_output_loss: 0.6172 - footwear_output_loss: 0.6521 - pose_output_loss: 0.2970 - emotion_output_loss: 0.7407 - gender_output_acc: 0.9147 - image_quality_output_acc: 0.6200 - age_output_acc: 0.5132 - weight_output_acc: 0.6975 - bag_output_acc: 0.7474 - footwear_output_acc: 0.7154 - pose_output_acc: 0.8852 - emotion_output_acc: 0.7267 - val_loss: 7.0054 - val_gender_output_loss: 0.4201 - val_image_quality_output_loss: 0.9743 - val_age_output_loss: 1.4159 - val_weight_output_loss: 0.9903 - val_bag_output_loss: 0.8546 - val_footwear_output_loss: 0.8695 - val_pose_output_loss: 0.5406 - val_emotion_output_loss: 0.9400 - val_gender_output_acc: 0.8292 - val_image_quality_output_acc: 0.5193 - val_age_output_acc: 0.3850 - val_weight_output_acc: 0.6146 - val_bag_output_acc: 0.6403 - val_footwear_output_acc: 0.6220 - val_pose_output_acc: 0.8028 - val_emotion_output_acc: 0.6838\n",
            "Epoch 45/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 5.1868 - gender_output_loss: 0.2054 - image_quality_output_loss: 0.8048 - age_output_loss: 1.1415 - weight_output_loss: 0.7480 - bag_output_loss: 0.6218 - footwear_output_loss: 0.6444 - pose_output_loss: 0.2806 - emotion_output_loss: 0.7404 - gender_output_acc: 0.9181 - image_quality_output_acc: 0.6268 - age_output_acc: 0.5126 - weight_output_acc: 0.6948 - bag_output_acc: 0.7460 - footwear_output_acc: 0.7194 - pose_output_acc: 0.8935 - emotion_output_acc: 0.7277 - val_loss: 7.0260 - val_gender_output_loss: 0.4211 - val_image_quality_output_loss: 0.9861 - val_age_output_loss: 1.4074 - val_weight_output_loss: 0.9872 - val_bag_output_loss: 0.8567 - val_footwear_output_loss: 0.8782 - val_pose_output_loss: 0.5471 - val_emotion_output_loss: 0.9421 - val_gender_output_acc: 0.8300 - val_image_quality_output_acc: 0.5327 - val_age_output_acc: 0.3962 - val_weight_output_acc: 0.6202 - val_bag_output_acc: 0.6417 - val_footwear_output_acc: 0.6153 - val_pose_output_acc: 0.7954 - val_emotion_output_acc: 0.6942\n",
            "\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 5.2012 - gender_output_loss: 0.2094 - image_quality_output_loss: 0.8077 - age_output_loss: 1.1364 - weight_output_loss: 0.7408 - bag_output_loss: 0.6172 - footwear_output_loss: 0.6521 - pose_output_loss: 0.2970 - emotion_output_loss: 0.7407 - gender_output_acc: 0.9147 - image_quality_output_acc: 0.6200 - age_output_acc: 0.5132 - weight_output_acc: 0.6975 - bag_output_acc: 0.7474 - footwear_output_acc: 0.7154 - pose_output_acc: 0.8852 - emotion_output_acc: 0.7267 - val_loss: 7.0054 - val_gender_output_loss: 0.4201 - val_image_quality_output_loss: 0.9743 - val_age_output_loss: 1.4159 - val_weight_output_loss: 0.9903 - val_bag_output_loss: 0.8546 - val_footwear_output_loss: 0.8695 - val_pose_output_loss: 0.5406 - val_emotion_output_loss: 0.9400 - val_gender_output_acc: 0.8292 - val_image_quality_output_acc: 0.5193 - val_age_output_acc: 0.3850 - val_weight_output_acc: 0.6146 - val_bag_output_acc: 0.6403 - val_footwear_output_acc: 0.6220 - val_pose_output_acc: 0.8028 - val_emotion_output_acc: 0.6838\n",
            "Epoch 46/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 5.1678 - gender_output_loss: 0.2055 - image_quality_output_loss: 0.8026 - age_output_loss: 1.1414 - weight_output_loss: 0.7383 - bag_output_loss: 0.6186 - footwear_output_loss: 0.6406 - pose_output_loss: 0.2828 - emotion_output_loss: 0.7381 - gender_output_acc: 0.9150 - image_quality_output_acc: 0.6256 - age_output_acc: 0.5152 - weight_output_acc: 0.6990 - bag_output_acc: 0.7452 - footwear_output_acc: 0.7188 - pose_output_acc: 0.8876 - emotion_output_acc: 0.7274 - val_loss: 7.0103 - val_gender_output_loss: 0.4264 - val_image_quality_output_loss: 0.9679 - val_age_output_loss: 1.4092 - val_weight_output_loss: 0.9902 - val_bag_output_loss: 0.8562 - val_footwear_output_loss: 0.8740 - val_pose_output_loss: 0.5439 - val_emotion_output_loss: 0.9424 - val_gender_output_acc: 0.8300 - val_image_quality_output_acc: 0.5335 - val_age_output_acc: 0.3903 - val_weight_output_acc: 0.6109 - val_bag_output_acc: 0.6484 - val_footwear_output_acc: 0.6183 - val_pose_output_acc: 0.8073 - val_emotion_output_acc: 0.6827\n",
            "Epoch 47/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 5.1420 - gender_output_loss: 0.2047 - image_quality_output_loss: 0.8056 - age_output_loss: 1.1324 - weight_output_loss: 0.7353 - bag_output_loss: 0.6116 - footwear_output_loss: 0.6360 - pose_output_loss: 0.2789 - emotion_output_loss: 0.7375 - gender_output_acc: 0.9164 - image_quality_output_acc: 0.6223 - age_output_acc: 0.5196 - weight_output_acc: 0.6965 - bag_output_acc: 0.7498 - footwear_output_acc: 0.7193 - pose_output_acc: 0.8922 - emotion_output_acc: 0.7256 - val_loss: 7.0865 - val_gender_output_loss: 0.4342 - val_image_quality_output_loss: 1.0114 - val_age_output_loss: 1.4063 - val_weight_output_loss: 0.9926 - val_bag_output_loss: 0.8611 - val_footwear_output_loss: 0.8784 - val_pose_output_loss: 0.5547 - val_emotion_output_loss: 0.9478 - val_gender_output_acc: 0.8244 - val_image_quality_output_acc: 0.5167 - val_age_output_acc: 0.3895 - val_weight_output_acc: 0.6190 - val_bag_output_acc: 0.6432 - val_footwear_output_acc: 0.6146 - val_pose_output_acc: 0.7965 - val_emotion_output_acc: 0.6964\n",
            "Epoch 48/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 5.1445 - gender_output_loss: 0.2046 - image_quality_output_loss: 0.7999 - age_output_loss: 1.1309 - weight_output_loss: 0.7374 - bag_output_loss: 0.6125 - footwear_output_loss: 0.6349 - pose_output_loss: 0.2866 - emotion_output_loss: 0.7377 - gender_output_acc: 0.9126 - image_quality_output_acc: 0.6302 - age_output_acc: 0.5170 - weight_output_acc: 0.6951 - bag_output_acc: 0.7485 - footwear_output_acc: 0.7290 - pose_output_acc: 0.8874 - emotion_output_acc: 0.7277 - val_loss: 7.0510 - val_gender_output_loss: 0.4315 - val_image_quality_output_loss: 0.9906 - val_age_output_loss: 1.4064 - val_weight_output_loss: 0.9898 - val_bag_output_loss: 0.8583 - val_footwear_output_loss: 0.8783 - val_pose_output_loss: 0.5494 - val_emotion_output_loss: 0.9469 - val_gender_output_acc: 0.8296 - val_image_quality_output_acc: 0.5190 - val_age_output_acc: 0.4007 - val_weight_output_acc: 0.6116 - val_bag_output_acc: 0.6488 - val_footwear_output_acc: 0.6157 - val_pose_output_acc: 0.7976 - val_emotion_output_acc: 0.6834\n",
            "\n",
            "Epoch 48/100\n",
            "Learning rate:  0.001\n",
            "Epoch 49/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 5.1030 - gender_output_loss: 0.2009 - image_quality_output_loss: 0.7921 - age_output_loss: 1.1323 - weight_output_loss: 0.7229 - bag_output_loss: 0.6028 - footwear_output_loss: 0.6381 - pose_output_loss: 0.2806 - emotion_output_loss: 0.7333 - gender_output_acc: 0.9173 - image_quality_output_acc: 0.6327 - age_output_acc: 0.5150 - weight_output_acc: 0.7030 - bag_output_acc: 0.7515 - footwear_output_acc: 0.7258 - pose_output_acc: 0.8911 - emotion_output_acc: 0.7270 - val_loss: 7.0562 - val_gender_output_loss: 0.4155 - val_image_quality_output_loss: 0.9843 - val_age_output_loss: 1.4181 - val_weight_output_loss: 0.9953 - val_bag_output_loss: 0.8629 - val_footwear_output_loss: 0.8836 - val_pose_output_loss: 0.5527 - val_emotion_output_loss: 0.9438 - val_gender_output_acc: 0.8296 - val_image_quality_output_acc: 0.5376 - val_age_output_acc: 0.3865 - val_weight_output_acc: 0.6190 - val_bag_output_acc: 0.6417 - val_footwear_output_acc: 0.6097 - val_pose_output_acc: 0.7958 - val_emotion_output_acc: 0.6894\n",
            "Epoch 49/100\n",
            "Learning rate:  0.001\n",
            "Epoch 50/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 5.0701 - gender_output_loss: 0.2000 - image_quality_output_loss: 0.7899 - age_output_loss: 1.1207 - weight_output_loss: 0.7217 - bag_output_loss: 0.6070 - footwear_output_loss: 0.6347 - pose_output_loss: 0.2729 - emotion_output_loss: 0.7234 - gender_output_acc: 0.9203 - image_quality_output_acc: 0.6321 - age_output_acc: 0.5249 - weight_output_acc: 0.7074 - bag_output_acc: 0.7498 - footwear_output_acc: 0.7266 - pose_output_acc: 0.8950 - emotion_output_acc: 0.7303 - val_loss: 7.1294 - val_gender_output_loss: 0.4365 - val_image_quality_output_loss: 1.0083 - val_age_output_loss: 1.4139 - val_weight_output_loss: 1.0012 - val_bag_output_loss: 0.8737 - val_footwear_output_loss: 0.8795 - val_pose_output_loss: 0.5654 - val_emotion_output_loss: 0.9509 - val_gender_output_acc: 0.8251 - val_image_quality_output_acc: 0.5167 - val_age_output_acc: 0.3910 - val_weight_output_acc: 0.6205 - val_bag_output_acc: 0.6421 - val_footwear_output_acc: 0.6187 - val_pose_output_acc: 0.7961 - val_emotion_output_acc: 0.6897\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 5.0613 - gender_output_loss: 0.2016 - image_quality_output_loss: 0.7921 - age_output_loss: 1.1169 - weight_output_loss: 0.7225 - bag_output_loss: 0.5993 - footwear_output_loss: 0.6264 - pose_output_loss: 0.2716 - emotion_output_loss: 0.7308 - gender_output_acc: 0.9154 - image_quality_output_acc: 0.6381 - age_output_acc: 0.5195 - weight_output_acc: 0.7053 - bag_output_acc: 0.7544 - footwear_output_acc: 0.7257 - pose_output_acc: 0.8933 - emotion_output_acc: 0.7303 - val_loss: 7.1173 - val_gender_output_loss: 0.4304 - val_image_quality_output_loss: 0.9955 - val_age_output_loss: 1.4173 - val_weight_output_loss: 0.9998 - val_bag_output_loss: 0.8715 - val_footwear_output_loss: 0.8880 - val_pose_output_loss: 0.5641 - val_emotion_output_loss: 0.9507 - val_gender_output_acc: 0.8240 - val_image_quality_output_acc: 0.5156 - val_age_output_acc: 0.4010 - val_weight_output_acc: 0.6194 - val_bag_output_acc: 0.6436 - val_footwear_output_acc: 0.6257 - val_pose_output_acc: 0.8043 - val_emotion_output_acc: 0.6845\n",
            "Learning rate:  0.001\n",
            "Epoch 52/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 114ms/step - loss: 5.0500 - gender_output_loss: 0.2012 - image_quality_output_loss: 0.7932 - age_output_loss: 1.1107 - weight_output_loss: 0.7258 - bag_output_loss: 0.5979 - footwear_output_loss: 0.6251 - pose_output_loss: 0.2736 - emotion_output_loss: 0.7224 - gender_output_acc: 0.9159 - image_quality_output_acc: 0.6337 - age_output_acc: 0.5279 - weight_output_acc: 0.7032 - bag_output_acc: 0.7496 - footwear_output_acc: 0.7309 - pose_output_acc: 0.8979 - emotion_output_acc: 0.7315 - val_loss: 7.1170 - val_gender_output_loss: 0.4362 - val_image_quality_output_loss: 0.9808 - val_age_output_loss: 1.4283 - val_weight_output_loss: 1.0056 - val_bag_output_loss: 0.8701 - val_footwear_output_loss: 0.8878 - val_pose_output_loss: 0.5599 - val_emotion_output_loss: 0.9483 - val_gender_output_acc: 0.8315 - val_image_quality_output_acc: 0.5275 - val_age_output_acc: 0.3865 - val_weight_output_acc: 0.6083 - val_bag_output_acc: 0.6451 - val_footwear_output_acc: 0.6138 - val_pose_output_acc: 0.8028 - val_emotion_output_acc: 0.6953\n",
            "Epoch 53/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 5.0421 - gender_output_loss: 0.1981 - image_quality_output_loss: 0.7834 - age_output_loss: 1.1097 - weight_output_loss: 0.7229 - bag_output_loss: 0.5985 - footwear_output_loss: 0.6346 - pose_output_loss: 0.2707 - emotion_output_loss: 0.7242 - gender_output_acc: 0.9193 - image_quality_output_acc: 0.6362 - age_output_acc: 0.5342 - weight_output_acc: 0.7031 - bag_output_acc: 0.7504 - footwear_output_acc: 0.7305 - pose_output_acc: 0.8952 - emotion_output_acc: 0.7311 - val_loss: 7.1191 - val_gender_output_loss: 0.4237 - val_image_quality_output_loss: 1.0087 - val_age_output_loss: 1.4234 - val_weight_output_loss: 1.0032 - val_bag_output_loss: 0.8674 - val_footwear_output_loss: 0.8848 - val_pose_output_loss: 0.5588 - val_emotion_output_loss: 0.9493 - val_gender_output_acc: 0.8326 - val_image_quality_output_acc: 0.5219 - val_age_output_acc: 0.3858 - val_weight_output_acc: 0.6109 - val_bag_output_acc: 0.6458 - val_footwear_output_acc: 0.6187 - val_pose_output_acc: 0.7972 - val_emotion_output_acc: 0.6938\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 54/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 5.0298 - gender_output_loss: 0.2011 - image_quality_output_loss: 0.7873 - age_output_loss: 1.1065 - weight_output_loss: 0.7198 - bag_output_loss: 0.5944 - footwear_output_loss: 0.6208 - pose_output_loss: 0.2733 - emotion_output_loss: 0.7267 - gender_output_acc: 0.9163 - image_quality_output_acc: 0.6342 - age_output_acc: 0.5303 - weight_output_acc: 0.7064 - bag_output_acc: 0.7558 - footwear_output_acc: 0.7315 - pose_output_acc: 0.8945 - emotion_output_acc: 0.7297 - val_loss: 7.1468 - val_gender_output_loss: 0.4291 - val_image_quality_output_loss: 0.9905 - val_age_output_loss: 1.4264 - val_weight_output_loss: 1.0115 - val_bag_output_loss: 0.8719 - val_footwear_output_loss: 0.8936 - val_pose_output_loss: 0.5653 - val_emotion_output_loss: 0.9586 - val_gender_output_acc: 0.8333 - val_image_quality_output_acc: 0.5294 - val_age_output_acc: 0.3917 - val_weight_output_acc: 0.6045 - val_bag_output_acc: 0.6462 - val_footwear_output_acc: 0.6194 - val_pose_output_acc: 0.7991 - val_emotion_output_acc: 0.6771\n",
            "Epoch 55/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 5.0207 - gender_output_loss: 0.1997 - image_quality_output_loss: 0.7802 - age_output_loss: 1.1120 - weight_output_loss: 0.7193 - bag_output_loss: 0.5956 - footwear_output_loss: 0.6185 - pose_output_loss: 0.2692 - emotion_output_loss: 0.7263 - gender_output_acc: 0.9179 - image_quality_output_acc: 0.6451 - age_output_acc: 0.5242 - weight_output_acc: 0.7102 - bag_output_acc: 0.7552 - footwear_output_acc: 0.7325 - pose_output_acc: 0.8930 - emotion_output_acc: 0.7309 - val_loss: 7.1636 - val_gender_output_loss: 0.4363 - val_image_quality_output_loss: 1.0017 - val_age_output_loss: 1.4321 - val_weight_output_loss: 1.0051 - val_bag_output_loss: 0.8779 - val_footwear_output_loss: 0.8902 - val_pose_output_loss: 0.5663 - val_emotion_output_loss: 0.9540 - val_gender_output_acc: 0.8263 - val_image_quality_output_acc: 0.5305 - val_age_output_acc: 0.3932 - val_weight_output_acc: 0.6068 - val_bag_output_acc: 0.6432 - val_footwear_output_acc: 0.6224 - val_pose_output_acc: 0.7946 - val_emotion_output_acc: 0.6920\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 4.9875 - gender_output_loss: 0.1940 - image_quality_output_loss: 0.7828 - age_output_loss: 1.0968 - weight_output_loss: 0.7101 - bag_output_loss: 0.5912 - footwear_output_loss: 0.6239 - pose_output_loss: 0.2690 - emotion_output_loss: 0.7198 - gender_output_acc: 0.9210 - image_quality_output_acc: 0.6345 - age_output_acc: 0.5365 - weight_output_acc: 0.7105 - bag_output_acc: 0.7542 - footwear_output_acc: 0.7315 - pose_output_acc: 0.8965 - emotion_output_acc: 0.7345Learning rate:  0.001\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.9903 - gender_output_loss: 0.1944 - image_quality_output_loss: 0.7830 - age_output_loss: 1.0968 - weight_output_loss: 0.7104 - bag_output_loss: 0.5919 - footwear_output_loss: 0.6241 - pose_output_loss: 0.2690 - emotion_output_loss: 0.7208 - gender_output_acc: 0.9207 - image_quality_output_acc: 0.6344 - age_output_acc: 0.5365 - weight_output_acc: 0.7103 - bag_output_acc: 0.7542 - footwear_output_acc: 0.7314 - pose_output_acc: 0.8967 - emotion_output_acc: 0.7340 - val_loss: 7.1497 - val_gender_output_loss: 0.4375 - val_image_quality_output_loss: 0.9974 - val_age_output_loss: 1.4240 - val_weight_output_loss: 1.0067 - val_bag_output_loss: 0.8734 - val_footwear_output_loss: 0.8905 - val_pose_output_loss: 0.5640 - val_emotion_output_loss: 0.9562 - val_gender_output_acc: 0.8281 - val_image_quality_output_acc: 0.5246 - val_age_output_acc: 0.3884 - val_weight_output_acc: 0.6172 - val_bag_output_acc: 0.6436 - val_footwear_output_acc: 0.6150 - val_pose_output_acc: 0.8013 - val_emotion_output_acc: 0.6882\n",
            "Epoch 57/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 4.9847 - gender_output_loss: 0.1897 - image_quality_output_loss: 0.7822 - age_output_loss: 1.1025 - weight_output_loss: 0.7189 - bag_output_loss: 0.5901 - footwear_output_loss: 0.6145 - pose_output_loss: 0.2651 - emotion_output_loss: 0.7217 - gender_output_acc: 0.9223 - image_quality_output_acc: 0.6439 - age_output_acc: 0.5319 - weight_output_acc: 0.7077 - bag_output_acc: 0.7571 - footwear_output_acc: 0.7340 - pose_output_acc: 0.8964 - emotion_output_acc: 0.7347\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.9837 - gender_output_loss: 0.1898 - image_quality_output_loss: 0.7820 - age_output_loss: 1.1022 - weight_output_loss: 0.7182 - bag_output_loss: 0.5898 - footwear_output_loss: 0.6148 - pose_output_loss: 0.2649 - emotion_output_loss: 0.7220 - gender_output_acc: 0.9223 - image_quality_output_acc: 0.6438 - age_output_acc: 0.5322 - weight_output_acc: 0.7081 - bag_output_acc: 0.7573 - footwear_output_acc: 0.7341 - pose_output_acc: 0.8964 - emotion_output_acc: 0.7346 - val_loss: 7.1469 - val_gender_output_loss: 0.4362 - val_image_quality_output_loss: 0.9827 - val_age_output_loss: 1.4253 - val_weight_output_loss: 1.0030 - val_bag_output_loss: 0.8800 - val_footwear_output_loss: 0.8934 - val_pose_output_loss: 0.5701 - val_emotion_output_loss: 0.9563 - val_gender_output_acc: 0.8274 - val_image_quality_output_acc: 0.5331 - val_age_output_acc: 0.3865 - val_weight_output_acc: 0.6083 - val_bag_output_acc: 0.6440 - val_footwear_output_acc: 0.6168 - val_pose_output_acc: 0.8021 - val_emotion_output_acc: 0.6771\n",
            "Epoch 58/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 4.9444 - gender_output_loss: 0.1919 - image_quality_output_loss: 0.7772 - age_output_loss: 1.0910 - weight_output_loss: 0.7091 - bag_output_loss: 0.5824 - footwear_output_loss: 0.6067 - pose_output_loss: 0.2681 - emotion_output_loss: 0.7179 - gender_output_acc: 0.9195 - image_quality_output_acc: 0.6387 - age_output_acc: 0.5372 - weight_output_acc: 0.7090 - bag_output_acc: 0.7616 - footwear_output_acc: 0.7429 - pose_output_acc: 0.8975 - emotion_output_acc: 0.7334Epoch 58/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.9461 - gender_output_loss: 0.1917 - image_quality_output_loss: 0.7772 - age_output_loss: 1.0911 - weight_output_loss: 0.7096 - bag_output_loss: 0.5825 - footwear_output_loss: 0.6073 - pose_output_loss: 0.2684 - emotion_output_loss: 0.7184 - gender_output_acc: 0.9196 - image_quality_output_acc: 0.6386 - age_output_acc: 0.5369 - weight_output_acc: 0.7089 - bag_output_acc: 0.7614 - footwear_output_acc: 0.7427 - pose_output_acc: 0.8974 - emotion_output_acc: 0.7330 - val_loss: 7.1552 - val_gender_output_loss: 0.4364 - val_image_quality_output_loss: 0.9867 - val_age_output_loss: 1.4325 - val_weight_output_loss: 1.0051 - val_bag_output_loss: 0.8731 - val_footwear_output_loss: 0.8937 - val_pose_output_loss: 0.5704 - val_emotion_output_loss: 0.9574 - val_gender_output_acc: 0.8311 - val_image_quality_output_acc: 0.5264 - val_age_output_acc: 0.3880 - val_weight_output_acc: 0.6083 - val_bag_output_acc: 0.6507 - val_footwear_output_acc: 0.6135 - val_pose_output_acc: 0.7987 - val_emotion_output_acc: 0.6737\n",
            "Epoch 59/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.9365 - gender_output_loss: 0.1891 - image_quality_output_loss: 0.7759 - age_output_loss: 1.0932 - weight_output_loss: 0.7073 - bag_output_loss: 0.5764 - footwear_output_loss: 0.6123 - pose_output_loss: 0.2666 - emotion_output_loss: 0.7156 - gender_output_acc: 0.9228 - image_quality_output_acc: 0.6421 - age_output_acc: 0.5309 - weight_output_acc: 0.7141 - bag_output_acc: 0.7672 - footwear_output_acc: 0.7367 - pose_output_acc: 0.8984 - emotion_output_acc: 0.7356 - val_loss: 7.2508 - val_gender_output_loss: 0.4696 - val_image_quality_output_loss: 1.0035 - val_age_output_loss: 1.4298 - val_weight_output_loss: 1.0147 - val_bag_output_loss: 0.8948 - val_footwear_output_loss: 0.8990 - val_pose_output_loss: 0.5780 - val_emotion_output_loss: 0.9614 - val_gender_output_acc: 0.8233 - val_image_quality_output_acc: 0.5227 - val_age_output_acc: 0.3839 - val_weight_output_acc: 0.6235 - val_bag_output_acc: 0.6380 - val_footwear_output_acc: 0.6090 - val_pose_output_acc: 0.7935 - val_emotion_output_acc: 0.6864\n",
            "Epoch 60/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.9345 - gender_output_loss: 0.1958 - image_quality_output_loss: 0.7680 - age_output_loss: 1.0998 - weight_output_loss: 0.7035 - bag_output_loss: 0.5855 - footwear_output_loss: 0.6099 - pose_output_loss: 0.2642 - emotion_output_loss: 0.7078 - gender_output_acc: 0.9194 - image_quality_output_acc: 0.6506 - age_output_acc: 0.5375 - weight_output_acc: 0.7121 - bag_output_acc: 0.7602 - footwear_output_acc: 0.7393 - pose_output_acc: 0.8968 - emotion_output_acc: 0.7369 - val_loss: 7.1947 - val_gender_output_loss: 0.4382 - val_image_quality_output_loss: 0.9958 - val_age_output_loss: 1.4331 - val_weight_output_loss: 1.0108 - val_bag_output_loss: 0.8846 - val_footwear_output_loss: 0.8981 - val_pose_output_loss: 0.5734 - val_emotion_output_loss: 0.9607 - val_gender_output_acc: 0.8263 - val_image_quality_output_acc: 0.5335 - val_age_output_acc: 0.3906 - val_weight_output_acc: 0.6164 - val_bag_output_acc: 0.6384 - val_footwear_output_acc: 0.6109 - val_pose_output_acc: 0.8002 - val_emotion_output_acc: 0.6935\n",
            "Epoch 61/100\n",
            "Epoch 60/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.9182 - gender_output_loss: 0.1951 - image_quality_output_loss: 0.7723 - age_output_loss: 1.0970 - weight_output_loss: 0.7019 - bag_output_loss: 0.5795 - footwear_output_loss: 0.6051 - pose_output_loss: 0.2566 - emotion_output_loss: 0.7108 - gender_output_acc: 0.9199 - image_quality_output_acc: 0.6399 - age_output_acc: 0.5340 - weight_output_acc: 0.7119 - bag_output_acc: 0.7630 - footwear_output_acc: 0.7411 - pose_output_acc: 0.9020 - emotion_output_acc: 0.7374 - val_loss: 7.1848 - val_gender_output_loss: 0.4417 - val_image_quality_output_loss: 1.0015 - val_age_output_loss: 1.4324 - val_weight_output_loss: 1.0141 - val_bag_output_loss: 0.8805 - val_footwear_output_loss: 0.8943 - val_pose_output_loss: 0.5641 - val_emotion_output_loss: 0.9563 - val_gender_output_acc: 0.8304 - val_image_quality_output_acc: 0.5227 - val_age_output_acc: 0.3813 - val_weight_output_acc: 0.6120 - val_bag_output_acc: 0.6395 - val_footwear_output_acc: 0.6101 - val_pose_output_acc: 0.8058 - val_emotion_output_acc: 0.6871\n",
            "Learning rate:  0.001\n",
            "Epoch 62/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 4.8923 - gender_output_loss: 0.1859 - image_quality_output_loss: 0.7757 - age_output_loss: 1.0820 - weight_output_loss: 0.7009 - bag_output_loss: 0.5761 - footwear_output_loss: 0.6093 - pose_output_loss: 0.2534 - emotion_output_loss: 0.7090 - gender_output_acc: 0.9235 - image_quality_output_acc: 0.6452 - age_output_acc: 0.5408 - weight_output_acc: 0.7128 - bag_output_acc: 0.7672 - footwear_output_acc: 0.7351 - pose_output_acc: 0.9008 - emotion_output_acc: 0.7353\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.8923 - gender_output_loss: 0.1859 - image_quality_output_loss: 0.7756 - age_output_loss: 1.0818 - weight_output_loss: 0.7010 - bag_output_loss: 0.5761 - footwear_output_loss: 0.6091 - pose_output_loss: 0.2536 - emotion_output_loss: 0.7092 - gender_output_acc: 0.9235 - image_quality_output_acc: 0.6451 - age_output_acc: 0.5410 - weight_output_acc: 0.7129 - bag_output_acc: 0.7671 - footwear_output_acc: 0.7350 - pose_output_acc: 0.9007 - emotion_output_acc: 0.7353 - val_loss: 7.2356 - val_gender_output_loss: 0.4513 - val_image_quality_output_loss: 1.0054 - val_age_output_loss: 1.4364 - val_weight_output_loss: 1.0215 - val_bag_output_loss: 0.8850 - val_footwear_output_loss: 0.8984 - val_pose_output_loss: 0.5740 - val_emotion_output_loss: 0.9637 - val_gender_output_acc: 0.8266 - val_image_quality_output_acc: 0.5219 - val_age_output_acc: 0.3917 - val_weight_output_acc: 0.6060 - val_bag_output_acc: 0.6432 - val_footwear_output_acc: 0.6142 - val_pose_output_acc: 0.7958 - val_emotion_output_acc: 0.6815\n",
            "Epoch 63/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.8758 - gender_output_loss: 0.1875 - image_quality_output_loss: 0.7653 - age_output_loss: 1.0721 - weight_output_loss: 0.6953 - bag_output_loss: 0.5819 - footwear_output_loss: 0.6063 - pose_output_loss: 0.2613 - emotion_output_loss: 0.7061 - gender_output_acc: 0.9230 - image_quality_output_acc: 0.6493 - age_output_acc: 0.5500 - weight_output_acc: 0.7162 - bag_output_acc: 0.7643 - footwear_output_acc: 0.7380 - pose_output_acc: 0.8967 - emotion_output_acc: 0.7353 - val_loss: 7.2185 - val_gender_output_loss: 0.4473 - val_image_quality_output_loss: 1.0005 - val_age_output_loss: 1.4383 - val_weight_output_loss: 1.0159 - val_bag_output_loss: 0.8869 - val_footwear_output_loss: 0.8950 - val_pose_output_loss: 0.5731 - val_emotion_output_loss: 0.9615 - val_gender_output_acc: 0.8315 - val_image_quality_output_acc: 0.5272 - val_age_output_acc: 0.3891 - val_weight_output_acc: 0.6213 - val_bag_output_acc: 0.6417 - val_footwear_output_acc: 0.6131 - val_pose_output_acc: 0.7898 - val_emotion_output_acc: 0.6901\n",
            "Epoch 64/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.001.\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.8605 - gender_output_loss: 0.1920 - image_quality_output_loss: 0.7636 - age_output_loss: 1.0784 - weight_output_loss: 0.6913 - bag_output_loss: 0.5719 - footwear_output_loss: 0.6005 - pose_output_loss: 0.2596 - emotion_output_loss: 0.7032 - gender_output_acc: 0.9220 - image_quality_output_acc: 0.6484 - age_output_acc: 0.5422 - weight_output_acc: 0.7199 - bag_output_acc: 0.7614 - footwear_output_acc: 0.7391 - pose_output_acc: 0.8974 - emotion_output_acc: 0.7416 - val_loss: 7.2357 - val_gender_output_loss: 0.4396 - val_image_quality_output_loss: 1.0050 - val_age_output_loss: 1.4419 - val_weight_output_loss: 1.0196 - val_bag_output_loss: 0.8869 - val_footwear_output_loss: 0.9035 - val_pose_output_loss: 0.5759 - val_emotion_output_loss: 0.9633 - val_gender_output_acc: 0.8281 - val_image_quality_output_acc: 0.5164 - val_age_output_acc: 0.3899 - val_weight_output_acc: 0.6090 - val_bag_output_acc: 0.6373 - val_footwear_output_acc: 0.6138 - val_pose_output_acc: 0.7917 - val_emotion_output_acc: 0.6778\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 65/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.8690 - gender_output_loss: 0.1909 - image_quality_output_loss: 0.7603 - age_output_loss: 1.0786 - weight_output_loss: 0.6877 - bag_output_loss: 0.5776 - footwear_output_loss: 0.6039 - pose_output_loss: 0.2688 - emotion_output_loss: 0.7013 - gender_output_acc: 0.9196 - image_quality_output_acc: 0.6525 - age_output_acc: 0.5401 - weight_output_acc: 0.7183 - bag_output_acc: 0.7601 - footwear_output_acc: 0.7416 - pose_output_acc: 0.8944 - emotion_output_acc: 0.7380 - val_loss: 7.2424 - val_gender_output_loss: 0.4438 - val_image_quality_output_loss: 1.0101 - val_age_output_loss: 1.4398 - val_weight_output_loss: 1.0206 - val_bag_output_loss: 0.8873 - val_footwear_output_loss: 0.9036 - val_pose_output_loss: 0.5724 - val_emotion_output_loss: 0.9648 - val_gender_output_acc: 0.8292 - val_image_quality_output_acc: 0.5283 - val_age_output_acc: 0.3891 - val_weight_output_acc: 0.6090 - val_bag_output_acc: 0.6339 - val_footwear_output_acc: 0.6116 - val_pose_output_acc: 0.7987 - val_emotion_output_acc: 0.6808\n",
            "Epoch 66/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.8205 - gender_output_loss: 0.1815 - image_quality_output_loss: 0.7617 - age_output_loss: 1.0633 - weight_output_loss: 0.6924 - bag_output_loss: 0.5735 - footwear_output_loss: 0.5898 - pose_output_loss: 0.2603 - emotion_output_loss: 0.6981 - gender_output_acc: 0.9266 - image_quality_output_acc: 0.6482 - age_output_acc: 0.5548 - weight_output_acc: 0.7165 - bag_output_acc: 0.7659 - footwear_output_acc: 0.7471 - pose_output_acc: 0.8996 - emotion_output_acc: 0.7401 - val_loss: 7.2498 - val_gender_output_loss: 0.4562 - val_image_quality_output_loss: 0.9972 - val_age_output_loss: 1.4421 - val_weight_output_loss: 1.0205 - val_bag_output_loss: 0.8879 - val_footwear_output_loss: 0.9064 - val_pose_output_loss: 0.5762 - val_emotion_output_loss: 0.9633 - val_gender_output_acc: 0.8289 - val_image_quality_output_acc: 0.5156 - val_age_output_acc: 0.3795 - val_weight_output_acc: 0.6060 - val_bag_output_acc: 0.6429 - val_footwear_output_acc: 0.6101 - val_pose_output_acc: 0.7943 - val_emotion_output_acc: 0.6771\n",
            "Epoch 67/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.8207 - gender_output_loss: 0.1833 - image_quality_output_loss: 0.7633 - age_output_loss: 1.0630 - weight_output_loss: 0.6955 - bag_output_loss: 0.5694 - footwear_output_loss: 0.5959 - pose_output_loss: 0.2545 - emotion_output_loss: 0.6959 - gender_output_acc: 0.9263 - image_quality_output_acc: 0.6478 - age_output_acc: 0.5513 - weight_output_acc: 0.7173 - bag_output_acc: 0.7683 - footwear_output_acc: 0.7416 - pose_output_acc: 0.9004 - emotion_output_acc: 0.7412 - val_loss: 7.2922 - val_gender_output_loss: 0.4546 - val_image_quality_output_loss: 1.0144 - val_age_output_loss: 1.4489 - val_weight_output_loss: 1.0257 - val_bag_output_loss: 0.8937 - val_footwear_output_loss: 0.9042 - val_pose_output_loss: 0.5817 - val_emotion_output_loss: 0.9690 - val_gender_output_acc: 0.8225 - val_image_quality_output_acc: 0.5223 - val_age_output_acc: 0.3891 - val_weight_output_acc: 0.6023 - val_bag_output_acc: 0.6399 - val_footwear_output_acc: 0.6068 - val_pose_output_acc: 0.7909 - val_emotion_output_acc: 0.6860\n",
            "Epoch 68/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 67/100\n",
            " 0.001\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.8126 - gender_output_loss: 0.1910 - image_quality_output_loss: 0.7576 - age_output_loss: 1.0729 - weight_output_loss: 0.6841 - bag_output_loss: 0.5663 - footwear_output_loss: 0.5942 - pose_output_loss: 0.2586 - emotion_output_loss: 0.6880 - gender_output_acc: 0.9204 - image_quality_output_acc: 0.6504 - age_output_acc: 0.5479 - weight_output_acc: 0.7199 - bag_output_acc: 0.7684 - footwear_output_acc: 0.7400 - pose_output_acc: 0.9003 - emotion_output_acc: 0.7392 - val_loss: 7.2688 - val_gender_output_loss: 0.4545 - val_image_quality_output_loss: 0.9996 - val_age_output_loss: 1.4458 - val_weight_output_loss: 1.0227 - val_bag_output_loss: 0.8956 - val_footwear_output_loss: 0.9023 - val_pose_output_loss: 0.5789 - val_emotion_output_loss: 0.9694 - val_gender_output_acc: 0.8311 - val_image_quality_output_acc: 0.5231 - val_age_output_acc: 0.3813 - val_weight_output_acc: 0.6031 - val_bag_output_acc: 0.6403 - val_footwear_output_acc: 0.6116 - val_pose_output_acc: 0.7984 - val_emotion_output_acc: 0.6715\n",
            "Epoch 69/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 4.8046 - gender_output_loss: 0.1852 - image_quality_output_loss: 0.7588 - age_output_loss: 1.0587 - weight_output_loss: 0.6890 - bag_output_loss: 0.5706 - footwear_output_loss: 0.5941 - pose_output_loss: 0.2572 - emotion_output_loss: 0.6909 - gender_output_acc: 0.9223 - image_quality_output_acc: 0.6571 - age_output_acc: 0.5585 - weight_output_acc: 0.7202 - bag_output_acc: 0.7648 - footwear_output_acc: 0.7494 - pose_output_acc: 0.8964 - emotion_output_acc: 0.7406\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.8041 - gender_output_loss: 0.1853 - image_quality_output_loss: 0.7590 - age_output_loss: 1.0583 - weight_output_loss: 0.6882 - bag_output_loss: 0.5706 - footwear_output_loss: 0.5947 - pose_output_loss: 0.2575 - emotion_output_loss: 0.6905 - gender_output_acc: 0.9223 - image_quality_output_acc: 0.6571 - age_output_acc: 0.5588 - weight_output_acc: 0.7208 - bag_output_acc: 0.7647 - footwear_output_acc: 0.7488 - pose_output_acc: 0.8963 - emotion_output_acc: 0.7408 - val_loss: 7.3665 - val_gender_output_loss: 0.4647 - val_image_quality_output_loss: 1.0413 - val_age_output_loss: 1.4516 - val_weight_output_loss: 1.0340 - val_bag_output_loss: 0.9018 - val_footwear_output_loss: 0.9087 - val_pose_output_loss: 0.5870 - val_emotion_output_loss: 0.9773 - val_gender_output_acc: 0.8229 - val_image_quality_output_acc: 0.5011 - val_age_output_acc: 0.3836 - val_weight_output_acc: 0.5990 - val_bag_output_acc: 0.6313 - val_footwear_output_acc: 0.6124 - val_pose_output_acc: 0.7879 - val_emotion_output_acc: 0.6912\n",
            "Epoch 70/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.7756 - gender_output_loss: 0.1817 - image_quality_output_loss: 0.7514 - age_output_loss: 1.0512 - weight_output_loss: 0.6901 - bag_output_loss: 0.5648 - footwear_output_loss: 0.5915 - pose_output_loss: 0.2481 - emotion_output_loss: 0.6968 - gender_output_acc: 0.9265 - image_quality_output_acc: 0.6569 - age_output_acc: 0.5572 - weight_output_acc: 0.7157 - bag_output_acc: 0.7695 - footwear_output_acc: 0.7480 - pose_output_acc: 0.9038 - emotion_output_acc: 0.7380 - val_loss: 7.3337 - val_gender_output_loss: 0.4850 - val_image_quality_output_loss: 1.0095 - val_age_output_loss: 1.4512 - val_weight_output_loss: 1.0293 - val_bag_output_loss: 0.8919 - val_footwear_output_loss: 0.9099 - val_pose_output_loss: 0.5854 - val_emotion_output_loss: 0.9715 - val_gender_output_acc: 0.8207 - val_image_quality_output_acc: 0.5242 - val_age_output_acc: 0.3798 - val_weight_output_acc: 0.6049 - val_bag_output_acc: 0.6421 - val_footwear_output_acc: 0.6101 - val_pose_output_acc: 0.7917 - val_emotion_output_acc: 0.6771\n",
            "Epoch 71/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.7748 - gender_output_loss: 0.1813 - image_quality_output_loss: 0.7500 - age_output_loss: 1.0621 - weight_output_loss: 0.6799 - bag_output_loss: 0.5687 - footwear_output_loss: 0.5941 - pose_output_loss: 0.2469 - emotion_output_loss: 0.6918 - gender_output_acc: 0.9271 - image_quality_output_acc: 0.6597 - age_output_acc: 0.5555 - weight_output_acc: 0.7184 - bag_output_acc: 0.7653 - footwear_output_acc: 0.7445 - pose_output_acc: 0.9053 - emotion_output_acc: 0.7416 - val_loss: 7.2882 - val_gender_output_loss: 0.4565 - val_image_quality_output_loss: 0.9944 - val_age_output_loss: 1.4574 - val_weight_output_loss: 1.0315 - val_bag_output_loss: 0.8898 - val_footwear_output_loss: 0.9096 - val_pose_output_loss: 0.5800 - val_emotion_output_loss: 0.9691 - val_gender_output_acc: 0.8233 - val_image_quality_output_acc: 0.5253 - val_age_output_acc: 0.3810 - val_weight_output_acc: 0.5975 - val_bag_output_acc: 0.6347 - val_footwear_output_acc: 0.6172 - val_pose_output_acc: 0.7898 - val_emotion_output_acc: 0.6864\n",
            "Epoch 71/100\n",
            "Learning rate:  \n",
            "Epoch 72/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.7514 - gender_output_loss: 0.1838 - image_quality_output_loss: 0.7545 - age_output_loss: 1.0556 - weight_output_loss: 0.6782 - bag_output_loss: 0.5558 - footwear_output_loss: 0.5884 - pose_output_loss: 0.2502 - emotion_output_loss: 0.6850 - gender_output_acc: 0.9266 - image_quality_output_acc: 0.6515 - age_output_acc: 0.5509 - weight_output_acc: 0.7240 - bag_output_acc: 0.7698 - footwear_output_acc: 0.7462 - pose_output_acc: 0.8977 - emotion_output_acc: 0.7408 - val_loss: 7.3148 - val_gender_output_loss: 0.4548 - val_image_quality_output_loss: 0.9945 - val_age_output_loss: 1.4557 - val_weight_output_loss: 1.0339 - val_bag_output_loss: 0.8983 - val_footwear_output_loss: 0.9139 - val_pose_output_loss: 0.5917 - val_emotion_output_loss: 0.9720 - val_gender_output_acc: 0.8274 - val_image_quality_output_acc: 0.5290 - val_age_output_acc: 0.3850 - val_weight_output_acc: 0.5949 - val_bag_output_acc: 0.6328 - val_footwear_output_acc: 0.6138 - val_pose_output_acc: 0.7876 - val_emotion_output_acc: 0.6752\n",
            "Epoch 73/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 72/100\n",
            "\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.7355 - gender_output_loss: 0.1792 - image_quality_output_loss: 0.7513 - age_output_loss: 1.0527 - weight_output_loss: 0.6777 - bag_output_loss: 0.5460 - footwear_output_loss: 0.5906 - pose_output_loss: 0.2513 - emotion_output_loss: 0.6866 - gender_output_acc: 0.9268 - image_quality_output_acc: 0.6527 - age_output_acc: 0.5558 - weight_output_acc: 0.7194 - bag_output_acc: 0.7789 - footwear_output_acc: 0.7408 - pose_output_acc: 0.9015 - emotion_output_acc: 0.7419 - val_loss: 7.3478 - val_gender_output_loss: 0.4489 - val_image_quality_output_loss: 1.0258 - val_age_output_loss: 1.4588 - val_weight_output_loss: 1.0327 - val_bag_output_loss: 0.9060 - val_footwear_output_loss: 0.9155 - val_pose_output_loss: 0.5865 - val_emotion_output_loss: 0.9736 - val_gender_output_acc: 0.8270 - val_image_quality_output_acc: 0.5175 - val_age_output_acc: 0.3795 - val_weight_output_acc: 0.6090 - val_bag_output_acc: 0.6410 - val_footwear_output_acc: 0.6101 - val_pose_output_acc: 0.7883 - val_emotion_output_acc: 0.6778\n",
            "Epoch 74/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 73/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.7087 - gender_output_loss: 0.1809 - image_quality_output_loss: 0.7395 - age_output_loss: 1.0447 - weight_output_loss: 0.6712 - bag_output_loss: 0.5587 - footwear_output_loss: 0.5865 - pose_output_loss: 0.2505 - emotion_output_loss: 0.6766 - gender_output_acc: 0.9256 - image_quality_output_acc: 0.6629 - age_output_acc: 0.5596 - weight_output_acc: 0.7277 - bag_output_acc: 0.7755 - footwear_output_acc: 0.7461 - pose_output_acc: 0.9009 - emotion_output_acc: 0.7456 - val_loss: 7.3719 - val_gender_output_loss: 0.4560 - val_image_quality_output_loss: 1.0261 - val_age_output_loss: 1.4610 - val_weight_output_loss: 1.0309 - val_bag_output_loss: 0.9076 - val_footwear_output_loss: 0.9167 - val_pose_output_loss: 0.5964 - val_emotion_output_loss: 0.9772 - val_gender_output_acc: 0.8270 - val_image_quality_output_acc: 0.5193 - val_age_output_acc: 0.3776 - val_weight_output_acc: 0.6034 - val_bag_output_acc: 0.6432 - val_footwear_output_acc: 0.6097 - val_pose_output_acc: 0.7958 - val_emotion_output_acc: 0.6708\n",
            "Epoch 75/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.7150 - gender_output_loss: 0.1831 - image_quality_output_loss: 0.7429 - age_output_loss: 1.0454 - weight_output_loss: 0.6743 - bag_output_loss: 0.5536 - footwear_output_loss: 0.5876 - pose_output_loss: 0.2457 - emotion_output_loss: 0.6823 - gender_output_acc: 0.9260 - image_quality_output_acc: 0.6578 - age_output_acc: 0.5616 - weight_output_acc: 0.7245 - bag_output_acc: 0.7742 - footwear_output_acc: 0.7469 - pose_output_acc: 0.9060 - emotion_output_acc: 0.7452 - val_loss: 7.3712 - val_gender_output_loss: 0.4674 - val_image_quality_output_loss: 1.0032 - val_age_output_loss: 1.4647 - val_weight_output_loss: 1.0407 - val_bag_output_loss: 0.9040 - val_footwear_output_loss: 0.9187 - val_pose_output_loss: 0.5915 - val_emotion_output_loss: 0.9810 - val_gender_output_acc: 0.8292 - val_image_quality_output_acc: 0.5275 - val_age_output_acc: 0.3806 - val_weight_output_acc: 0.5915 - val_bag_output_acc: 0.6376 - val_footwear_output_acc: 0.6164 - val_pose_output_acc: 0.7950 - val_emotion_output_acc: 0.6815\n",
            "Epoch 76/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.7165 - gender_output_loss: 0.1853 - image_quality_output_loss: 0.7464 - age_output_loss: 1.0433 - weight_output_loss: 0.6765 - bag_output_loss: 0.5523 - footwear_output_loss: 0.5867 - pose_output_loss: 0.2479 - emotion_output_loss: 0.6781 - gender_output_acc: 0.9228 - image_quality_output_acc: 0.6590 - age_output_acc: 0.5632 - weight_output_acc: 0.7217 - bag_output_acc: 0.7765 - footwear_output_acc: 0.7460 - pose_output_acc: 0.9031 - emotion_output_acc: 0.7448 - val_loss: 7.3961 - val_gender_output_loss: 0.4721 - val_image_quality_output_loss: 1.0025 - val_age_output_loss: 1.4674 - val_weight_output_loss: 1.0302 - val_bag_output_loss: 0.9177 - val_footwear_output_loss: 0.9213 - val_pose_output_loss: 0.6008 - val_emotion_output_loss: 0.9842 - val_gender_output_acc: 0.8233 - val_image_quality_output_acc: 0.5249 - val_age_output_acc: 0.3780 - val_weight_output_acc: 0.6045 - val_bag_output_acc: 0.6295 - val_footwear_output_acc: 0.6042 - val_pose_output_acc: 0.7950 - val_emotion_output_acc: 0.6600\n",
            "Epoch 77/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 76/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.6997 - gender_output_loss: 0.1770 - image_quality_output_loss: 0.7452 - age_output_loss: 1.0362 - weight_output_loss: 0.6701 - bag_output_loss: 0.5558 - footwear_output_loss: 0.5817 - pose_output_loss: 0.2479 - emotion_output_loss: 0.6857 - gender_output_acc: 0.9285 - image_quality_output_acc: 0.6629 - age_output_acc: 0.5654 - weight_output_acc: 0.7256 - bag_output_acc: 0.7713 - footwear_output_acc: 0.7527 - pose_output_acc: 0.9028 - emotion_output_acc: 0.7429 - val_loss: 7.3985 - val_gender_output_loss: 0.4781 - val_image_quality_output_loss: 0.9990 - val_age_output_loss: 1.4704 - val_weight_output_loss: 1.0451 - val_bag_output_loss: 0.9135 - val_footwear_output_loss: 0.9150 - val_pose_output_loss: 0.5981 - val_emotion_output_loss: 0.9793 - val_gender_output_acc: 0.8237 - val_image_quality_output_acc: 0.5353 - val_age_output_acc: 0.3806 - val_weight_output_acc: 0.5915 - val_bag_output_acc: 0.6310 - val_footwear_output_acc: 0.6168 - val_pose_output_acc: 0.7865 - val_emotion_output_acc: 0.6734\n",
            "Epoch 78/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 4.6716 - gender_output_loss: 0.1773 - image_quality_output_loss: 0.7384 - age_output_loss: 1.0377 - weight_output_loss: 0.6611 - bag_output_loss: 0.5506 - footwear_output_loss: 0.5822 - pose_output_loss: 0.2477 - emotion_output_loss: 0.6767 - gender_output_acc: 0.9275 - image_quality_output_acc: 0.6668 - age_output_acc: 0.5608 - weight_output_acc: 0.7305 - bag_output_acc: 0.7782 - footwear_output_acc: 0.7456 - pose_output_acc: 0.9043 - emotion_output_acc: 0.7481Epoch 78/100\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.6716 - gender_output_loss: 0.1777 - image_quality_output_loss: 0.7380 - age_output_loss: 1.0372 - weight_output_loss: 0.6608 - bag_output_loss: 0.5506 - footwear_output_loss: 0.5833 - pose_output_loss: 0.2473 - emotion_output_loss: 0.6768 - gender_output_acc: 0.9272 - image_quality_output_acc: 0.6670 - age_output_acc: 0.5612 - weight_output_acc: 0.7306 - bag_output_acc: 0.7782 - footwear_output_acc: 0.7451 - pose_output_acc: 0.9044 - emotion_output_acc: 0.7481 - val_loss: 7.4064 - val_gender_output_loss: 0.4622 - val_image_quality_output_loss: 1.0357 - val_age_output_loss: 1.4734 - val_weight_output_loss: 1.0422 - val_bag_output_loss: 0.9092 - val_footwear_output_loss: 0.9143 - val_pose_output_loss: 0.5911 - val_emotion_output_loss: 0.9782 - val_gender_output_acc: 0.8266 - val_image_quality_output_acc: 0.5108 - val_age_output_acc: 0.3810 - val_weight_output_acc: 0.5926 - val_bag_output_acc: 0.6399 - val_footwear_output_acc: 0.6146 - val_pose_output_acc: 0.7946 - val_emotion_output_acc: 0.6767\n",
            "\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 79/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 111ms/step - loss: 4.6601 - gender_output_loss: 0.1797 - image_quality_output_loss: 0.7440 - age_output_loss: 1.0348 - weight_output_loss: 0.6668 - bag_output_loss: 0.5459 - footwear_output_loss: 0.5792 - pose_output_loss: 0.2420 - emotion_output_loss: 0.6678 - gender_output_acc: 0.9266 - image_quality_output_acc: 0.6590 - age_output_acc: 0.5638 - weight_output_acc: 0.7286 - bag_output_acc: 0.7763 - footwear_output_acc: 0.7541 - pose_output_acc: 0.9040 - emotion_output_acc: 0.7476 - val_loss: 7.4839 - val_gender_output_loss: 0.4754 - val_image_quality_output_loss: 1.0703 - val_age_output_loss: 1.4711 - val_weight_output_loss: 1.0411 - val_bag_output_loss: 0.9137 - val_footwear_output_loss: 0.9236 - val_pose_output_loss: 0.5999 - val_emotion_output_loss: 0.9887 - val_gender_output_acc: 0.8233 - val_image_quality_output_acc: 0.4996 - val_age_output_acc: 0.3806 - val_weight_output_acc: 0.5990 - val_bag_output_acc: 0.6317 - val_footwear_output_acc: 0.6105 - val_pose_output_acc: 0.7846 - val_emotion_output_acc: 0.6615\n",
            "Learning rate:  0.001\n",
            "Epoch 80/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.6447 - gender_output_loss: 0.1777 - image_quality_output_loss: 0.7419 - age_output_loss: 1.0247 - weight_output_loss: 0.6642 - bag_output_loss: 0.5392 - footwear_output_loss: 0.5774 - pose_output_loss: 0.2472 - emotion_output_loss: 0.6724 - gender_output_acc: 0.9265 - image_quality_output_acc: 0.6585 - age_output_acc: 0.5732 - weight_output_acc: 0.7278 - bag_output_acc: 0.7813 - footwear_output_acc: 0.7542 - pose_output_acc: 0.9050 - emotion_output_acc: 0.7484 - val_loss: 7.4245 - val_gender_output_loss: 0.4704 - val_image_quality_output_loss: 1.0483 - val_age_output_loss: 1.4649 - val_weight_output_loss: 1.0348 - val_bag_output_loss: 0.9084 - val_footwear_output_loss: 0.9167 - val_pose_output_loss: 0.5979 - val_emotion_output_loss: 0.9831 - val_gender_output_acc: 0.8214 - val_image_quality_output_acc: 0.5097 - val_age_output_acc: 0.3817 - val_weight_output_acc: 0.6060 - val_bag_output_acc: 0.6358 - val_footwear_output_acc: 0.6142 - val_pose_output_acc: 0.7827 - val_emotion_output_acc: 0.6749\n",
            "Epoch 81/100Epoch 80/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 4.6358 - gender_output_loss: 0.1845 - image_quality_output_loss: 0.7380 - age_output_loss: 1.0253 - weight_output_loss: 0.6626 - bag_output_loss: 0.5464 - footwear_output_loss: 0.5713 - pose_output_loss: 0.2355 - emotion_output_loss: 0.6723 - gender_output_acc: 0.9252 - image_quality_output_acc: 0.6607 - age_output_acc: 0.5685 - weight_output_acc: 0.7305 - bag_output_acc: 0.7724 - footwear_output_acc: 0.7570 - pose_output_acc: 0.9086 - emotion_output_acc: 0.7471\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.6345 - gender_output_loss: 0.1844 - image_quality_output_loss: 0.7379 - age_output_loss: 1.0242 - weight_output_loss: 0.6635 - bag_output_loss: 0.5462 - footwear_output_loss: 0.5713 - pose_output_loss: 0.2355 - emotion_output_loss: 0.6715 - gender_output_acc: 0.9252 - image_quality_output_acc: 0.6608 - age_output_acc: 0.5691 - weight_output_acc: 0.7300 - bag_output_acc: 0.7727 - footwear_output_acc: 0.7572 - pose_output_acc: 0.9086 - emotion_output_acc: 0.7475 - val_loss: 7.4615 - val_gender_output_loss: 0.4571 - val_image_quality_output_loss: 1.0263 - val_age_output_loss: 1.4837 - val_weight_output_loss: 1.0480 - val_bag_output_loss: 0.9173 - val_footwear_output_loss: 0.9271 - val_pose_output_loss: 0.6141 - val_emotion_output_loss: 0.9880 - val_gender_output_acc: 0.8274 - val_image_quality_output_acc: 0.5171 - val_age_output_acc: 0.3739 - val_weight_output_acc: 0.5986 - val_bag_output_acc: 0.6365 - val_footwear_output_acc: 0.6157 - val_pose_output_acc: 0.7857 - val_emotion_output_acc: 0.6663\n",
            "Epoch 82/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.6234 - gender_output_loss: 0.1792 - image_quality_output_loss: 0.7346 - age_output_loss: 1.0203 - weight_output_loss: 0.6603 - bag_output_loss: 0.5372 - footwear_output_loss: 0.5809 - pose_output_loss: 0.2458 - emotion_output_loss: 0.6651 - gender_output_acc: 0.9273 - image_quality_output_acc: 0.6611 - age_output_acc: 0.5700 - weight_output_acc: 0.7354 - bag_output_acc: 0.7857 - footwear_output_acc: 0.7510 - pose_output_acc: 0.9031 - emotion_output_acc: 0.7501 - val_loss: 7.4411 - val_gender_output_loss: 0.4729 - val_image_quality_output_loss: 1.0197 - val_age_output_loss: 1.4814 - val_weight_output_loss: 1.0469 - val_bag_output_loss: 0.9115 - val_footwear_output_loss: 0.9202 - val_pose_output_loss: 0.6004 - val_emotion_output_loss: 0.9880 - val_gender_output_acc: 0.8289 - val_image_quality_output_acc: 0.5134 - val_age_output_acc: 0.3787 - val_weight_output_acc: 0.5986 - val_bag_output_acc: 0.6365 - val_footwear_output_acc: 0.6101 - val_pose_output_acc: 0.7846 - val_emotion_output_acc: 0.6815\n",
            "Epoch 83/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.6361 - gender_output_loss: 0.1794 - image_quality_output_loss: 0.7379 - age_output_loss: 1.0140 - weight_output_loss: 0.6639 - bag_output_loss: 0.5458 - footwear_output_loss: 0.5839 - pose_output_loss: 0.2375 - emotion_output_loss: 0.6737 - gender_output_acc: 0.9285 - image_quality_output_acc: 0.6586 - age_output_acc: 0.5808 - weight_output_acc: 0.7298 - bag_output_acc: 0.7756 - footwear_output_acc: 0.7503 - pose_output_acc: 0.9092 - emotion_output_acc: 0.7438 - val_loss: 7.4365 - val_gender_output_loss: 0.4569 - val_image_quality_output_loss: 1.0317 - val_age_output_loss: 1.4820 - val_weight_output_loss: 1.0457 - val_bag_output_loss: 0.9137 - val_footwear_output_loss: 0.9226 - val_pose_output_loss: 0.6018 - val_emotion_output_loss: 0.9820 - val_gender_output_acc: 0.8289 - val_image_quality_output_acc: 0.5119 - val_age_output_acc: 0.3795 - val_weight_output_acc: 0.6016 - val_bag_output_acc: 0.6336 - val_footwear_output_acc: 0.6179 - val_pose_output_acc: 0.7812 - val_emotion_output_acc: 0.6756\n",
            "Epoch 84/100\n",
            "Learning rate: \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 0.001\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.5990 - gender_output_loss: 0.1771 - image_quality_output_loss: 0.7371 - age_output_loss: 1.0212 - weight_output_loss: 0.6532 - bag_output_loss: 0.5349 - footwear_output_loss: 0.5737 - pose_output_loss: 0.2346 - emotion_output_loss: 0.6671 - gender_output_acc: 0.9261 - image_quality_output_acc: 0.6603 - age_output_acc: 0.5764 - weight_output_acc: 0.7275 - bag_output_acc: 0.7806 - footwear_output_acc: 0.7542 - pose_output_acc: 0.9086 - emotion_output_acc: 0.7525 - val_loss: 7.4477 - val_gender_output_loss: 0.4665 - val_image_quality_output_loss: 1.0135 - val_age_output_loss: 1.4887 - val_weight_output_loss: 1.0472 - val_bag_output_loss: 0.9147 - val_footwear_output_loss: 0.9273 - val_pose_output_loss: 0.6003 - val_emotion_output_loss: 0.9895 - val_gender_output_acc: 0.8225 - val_image_quality_output_acc: 0.5205 - val_age_output_acc: 0.3836 - val_weight_output_acc: 0.5978 - val_bag_output_acc: 0.6350 - val_footwear_output_acc: 0.6097 - val_pose_output_acc: 0.7920 - val_emotion_output_acc: 0.6603\n",
            "Epoch 85/100\n",
            "0.001\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.001.\n",
            "Learning rate: Learning rate:  0.001\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.6141 - gender_output_loss: 0.1821 - image_quality_output_loss: 0.7336 - age_output_loss: 1.0188 - weight_output_loss: 0.6576 - bag_output_loss: 0.5388 - footwear_output_loss: 0.5766 - pose_output_loss: 0.2461 - emotion_output_loss: 0.6604 - gender_output_acc: 0.9248 - image_quality_output_acc: 0.6640 - age_output_acc: 0.5750 - weight_output_acc: 0.7295 - bag_output_acc: 0.7785 - footwear_output_acc: 0.7493 - pose_output_acc: 0.9009 - emotion_output_acc: 0.7536 - val_loss: 7.4615 - val_gender_output_loss: 0.4662 - val_image_quality_output_loss: 1.0245 - val_age_output_loss: 1.4766 - val_weight_output_loss: 1.0427 - val_bag_output_loss: 0.9199 - val_footwear_output_loss: 0.9357 - val_pose_output_loss: 0.6120 - val_emotion_output_loss: 0.9838 - val_gender_output_acc: 0.8263 - val_image_quality_output_acc: 0.5119 - val_age_output_acc: 0.3903 - val_weight_output_acc: 0.6090 - val_bag_output_acc: 0.6276 - val_footwear_output_acc: 0.6112 - val_pose_output_acc: 0.7805 - val_emotion_output_acc: 0.6797\n",
            "Epoch 86/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.5915 - gender_output_loss: 0.1751 - image_quality_output_loss: 0.7290 - age_output_loss: 1.0213 - weight_output_loss: 0.6556 - bag_output_loss: 0.5409 - footwear_output_loss: 0.5643 - pose_output_loss: 0.2392 - emotion_output_loss: 0.6661 - gender_output_acc: 0.9287 - image_quality_output_acc: 0.6626 - age_output_acc: 0.5746 - weight_output_acc: 0.7336 - bag_output_acc: 0.7748 - footwear_output_acc: 0.7593 - pose_output_acc: 0.9047 - emotion_output_acc: 0.7507 - val_loss: 7.4371 - val_gender_output_loss: 0.4577 - val_image_quality_output_loss: 1.0241 - val_age_output_loss: 1.4774 - val_weight_output_loss: 1.0505 - val_bag_output_loss: 0.9147 - val_footwear_output_loss: 0.9298 - val_pose_output_loss: 0.5959 - val_emotion_output_loss: 0.9871 - val_gender_output_acc: 0.8259 - val_image_quality_output_acc: 0.5312 - val_age_output_acc: 0.3828 - val_weight_output_acc: 0.6086 - val_bag_output_acc: 0.6336 - val_footwear_output_acc: 0.6120 - val_pose_output_acc: 0.7887 - val_emotion_output_acc: 0.6685\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 87/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.5636 - gender_output_loss: 0.1735 - image_quality_output_loss: 0.7294 - age_output_loss: 1.0169 - weight_output_loss: 0.6485 - bag_output_loss: 0.5278 - footwear_output_loss: 0.5711 - pose_output_loss: 0.2337 - emotion_output_loss: 0.6628 - gender_output_acc: 0.9263 - image_quality_output_acc: 0.6695 - age_output_acc: 0.5744 - weight_output_acc: 0.7375 - bag_output_acc: 0.7820 - footwear_output_acc: 0.7522 - pose_output_acc: 0.9086 - emotion_output_acc: 0.7519 - val_loss: 7.5058 - val_gender_output_loss: 0.4856 - val_image_quality_output_loss: 1.0343 - val_age_output_loss: 1.4815 - val_weight_output_loss: 1.0540 - val_bag_output_loss: 0.9273 - val_footwear_output_loss: 0.9248 - val_pose_output_loss: 0.6087 - val_emotion_output_loss: 0.9896 - val_gender_output_acc: 0.8211 - val_image_quality_output_acc: 0.5112 - val_age_output_acc: 0.3810 - val_weight_output_acc: 0.5990 - val_bag_output_acc: 0.6310 - val_footwear_output_acc: 0.6112 - val_pose_output_acc: 0.7872 - val_emotion_output_acc: 0.6674\n",
            "Epoch 88/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.5536 - gender_output_loss: 0.1752 - image_quality_output_loss: 0.7268 - age_output_loss: 1.0103 - weight_output_loss: 0.6469 - bag_output_loss: 0.5305 - footwear_output_loss: 0.5694 - pose_output_loss: 0.2346 - emotion_output_loss: 0.6599 - gender_output_acc: 0.9277 - image_quality_output_acc: 0.6689 - age_output_acc: 0.5765 - weight_output_acc: 0.7347 - bag_output_acc: 0.7827 - footwear_output_acc: 0.7551 - pose_output_acc: 0.9091 - emotion_output_acc: 0.7541 - val_loss: 7.4933 - val_gender_output_loss: 0.4782 - val_image_quality_output_loss: 1.0237 - val_age_output_loss: 1.4857 - val_weight_output_loss: 1.0651 - val_bag_output_loss: 0.9214 - val_footwear_output_loss: 0.9262 - val_pose_output_loss: 0.6033 - val_emotion_output_loss: 0.9897 - val_gender_output_acc: 0.8222 - val_image_quality_output_acc: 0.5123 - val_age_output_acc: 0.3832 - val_weight_output_acc: 0.5878 - val_bag_output_acc: 0.6388 - val_footwear_output_acc: 0.6060 - val_pose_output_acc: 0.7876 - val_emotion_output_acc: 0.6700\n",
            "Epoch 88/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 89/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.5445 - gender_output_loss: 0.1773 - image_quality_output_loss: 0.7223 - age_output_loss: 1.0146 - weight_output_loss: 0.6455 - bag_output_loss: 0.5318 - footwear_output_loss: 0.5610 - pose_output_loss: 0.2335 - emotion_output_loss: 0.6585 - gender_output_acc: 0.9294 - image_quality_output_acc: 0.6708 - age_output_acc: 0.5730 - weight_output_acc: 0.7387 - bag_output_acc: 0.7829 - footwear_output_acc: 0.7600 - pose_output_acc: 0.9078 - emotion_output_acc: 0.7539 - val_loss: 7.5178 - val_gender_output_loss: 0.4804 - val_image_quality_output_loss: 1.0452 - val_age_output_loss: 1.4860 - val_weight_output_loss: 1.0586 - val_bag_output_loss: 0.9238 - val_footwear_output_loss: 0.9278 - val_pose_output_loss: 0.5999 - val_emotion_output_loss: 0.9961 - val_gender_output_acc: 0.8278 - val_image_quality_output_acc: 0.5089 - val_age_output_acc: 0.3724 - val_weight_output_acc: 0.6019 - val_bag_output_acc: 0.6373 - val_footwear_output_acc: 0.6083 - val_pose_output_acc: 0.7913 - val_emotion_output_acc: 0.6749\n",
            "Epoch 90/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.5455 - gender_output_loss: 0.1707 - image_quality_output_loss: 0.7251 - age_output_loss: 1.0019 - weight_output_loss: 0.6588 - bag_output_loss: 0.5278 - footwear_output_loss: 0.5666 - pose_output_loss: 0.2347 - emotion_output_loss: 0.6599 - gender_output_acc: 0.9306 - image_quality_output_acc: 0.6680 - age_output_acc: 0.5848 - weight_output_acc: 0.7311 - bag_output_acc: 0.7864 - footwear_output_acc: 0.7576 - pose_output_acc: 0.9060 - emotion_output_acc: 0.7539 - val_loss: 7.5730 - val_gender_output_loss: 0.4830 - val_image_quality_output_loss: 1.0623 - val_age_output_loss: 1.4853 - val_weight_output_loss: 1.0571 - val_bag_output_loss: 0.9475 - val_footwear_output_loss: 0.9346 - val_pose_output_loss: 0.6075 - val_emotion_output_loss: 0.9958 - val_gender_output_acc: 0.8222 - val_image_quality_output_acc: 0.5045 - val_age_output_acc: 0.3832 - val_weight_output_acc: 0.5938 - val_bag_output_acc: 0.6265 - val_footwear_output_acc: 0.6083 - val_pose_output_acc: 0.7887 - val_emotion_output_acc: 0.6812\n",
            "Learning rate:  0.001\n",
            "Epoch 91/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.5099 - gender_output_loss: 0.1707 - image_quality_output_loss: 0.7197 - age_output_loss: 0.9988 - weight_output_loss: 0.6471 - bag_output_loss: 0.5283 - footwear_output_loss: 0.5566 - pose_output_loss: 0.2368 - emotion_output_loss: 0.6518 - gender_output_acc: 0.9300 - image_quality_output_acc: 0.6750 - age_output_acc: 0.5798 - weight_output_acc: 0.7376 - bag_output_acc: 0.7848 - footwear_output_acc: 0.7617 - pose_output_acc: 0.9086 - emotion_output_acc: 0.7558 - val_loss: 7.6430 - val_gender_output_loss: 0.4865 - val_image_quality_output_loss: 1.0951 - val_age_output_loss: 1.4970 - val_weight_output_loss: 1.0638 - val_bag_output_loss: 0.9335 - val_footwear_output_loss: 0.9409 - val_pose_output_loss: 0.6233 - val_emotion_output_loss: 1.0031 - val_gender_output_acc: 0.8259 - val_image_quality_output_acc: 0.4970 - val_age_output_acc: 0.3824 - val_weight_output_acc: 0.5997 - val_bag_output_acc: 0.6373 - val_footwear_output_acc: 0.6045 - val_pose_output_acc: 0.7809 - val_emotion_output_acc: 0.6682\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 92/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.5237 - gender_output_loss: 0.1762 - image_quality_output_loss: 0.7204 - age_output_loss: 0.9973 - weight_output_loss: 0.6499 - bag_output_loss: 0.5340 - footwear_output_loss: 0.5602 - pose_output_loss: 0.2348 - emotion_output_loss: 0.6509 - gender_output_acc: 0.9277 - image_quality_output_acc: 0.6715 - age_output_acc: 0.5916 - weight_output_acc: 0.7373 - bag_output_acc: 0.7796 - footwear_output_acc: 0.7588 - pose_output_acc: 0.9060 - emotion_output_acc: 0.7555 - val_loss: 7.5232 - val_gender_output_loss: 0.4728 - val_image_quality_output_loss: 1.0452 - val_age_output_loss: 1.4910 - val_weight_output_loss: 1.0566 - val_bag_output_loss: 0.9240 - val_footwear_output_loss: 0.9327 - val_pose_output_loss: 0.6022 - val_emotion_output_loss: 0.9987 - val_gender_output_acc: 0.8296 - val_image_quality_output_acc: 0.5112 - val_age_output_acc: 0.3765 - val_weight_output_acc: 0.6004 - val_bag_output_acc: 0.6406 - val_footwear_output_acc: 0.6083 - val_pose_output_acc: 0.7969 - val_emotion_output_acc: 0.6615\n",
            "Epoch 93/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.001.\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 4.4918 - gender_output_loss: 0.1762 - image_quality_output_loss: 0.7117 - age_output_loss: 0.9896 - weight_output_loss: 0.6439 - bag_output_loss: 0.5285 - footwear_output_loss: 0.5606 - pose_output_loss: 0.2242 - emotion_output_loss: 0.6571 - gender_output_acc: 0.9267 - image_quality_output_acc: 0.6779 - age_output_acc: 0.5903 - weight_output_acc: 0.7377 - bag_output_acc: 0.7807 - footwear_output_acc: 0.7608 - pose_output_acc: 0.9109 - emotion_output_acc: 0.7519\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.4911 - gender_output_loss: 0.1760 - image_quality_output_loss: 0.7116 - age_output_loss: 0.9892 - weight_output_loss: 0.6435 - bag_output_loss: 0.5284 - footwear_output_loss: 0.5606 - pose_output_loss: 0.2242 - emotion_output_loss: 0.6576 - gender_output_acc: 0.9268 - image_quality_output_acc: 0.6778 - age_output_acc: 0.5908 - weight_output_acc: 0.7379 - bag_output_acc: 0.7808 - footwear_output_acc: 0.7608 - pose_output_acc: 0.9110 - emotion_output_acc: 0.7516 - val_loss: 7.5546 - val_gender_output_loss: 0.4729 - val_image_quality_output_loss: 1.0328 - val_age_output_loss: 1.4927 - val_weight_output_loss: 1.0617 - val_bag_output_loss: 0.9322 - val_footwear_output_loss: 0.9482 - val_pose_output_loss: 0.6114 - val_emotion_output_loss: 1.0026 - val_gender_output_acc: 0.8263 - val_image_quality_output_acc: 0.5212 - val_age_output_acc: 0.3791 - val_weight_output_acc: 0.6120 - val_bag_output_acc: 0.6302 - val_footwear_output_acc: 0.6034 - val_pose_output_acc: 0.7906 - val_emotion_output_acc: 0.6749\n",
            "Epoch 94/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 4.4911 - gender_output_loss: 0.1717 - image_quality_output_loss: 0.7178 - age_output_loss: 1.0002 - weight_output_loss: 0.6389 - bag_output_loss: 0.5189 - footwear_output_loss: 0.5566 - pose_output_loss: 0.2353 - emotion_output_loss: 0.6517 - gender_output_acc: 0.9293 - image_quality_output_acc: 0.6713 - age_output_acc: 0.5805 - weight_output_acc: 0.7393 - bag_output_acc: 0.7841 - footwear_output_acc: 0.7619 - pose_output_acc: 0.9062 - emotion_output_acc: 0.7523\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.4950 - gender_output_loss: 0.1719 - image_quality_output_loss: 0.7186 - age_output_loss: 1.0009 - weight_output_loss: 0.6391 - bag_output_loss: 0.5197 - footwear_output_loss: 0.5574 - pose_output_loss: 0.2351 - emotion_output_loss: 0.6523 - gender_output_acc: 0.9290 - image_quality_output_acc: 0.6709 - age_output_acc: 0.5800 - weight_output_acc: 0.7390 - bag_output_acc: 0.7841 - footwear_output_acc: 0.7616 - pose_output_acc: 0.9063 - emotion_output_acc: 0.7519 - val_loss: 7.5295 - val_gender_output_loss: 0.4672 - val_image_quality_output_loss: 1.0264 - val_age_output_loss: 1.5019 - val_weight_output_loss: 1.0620 - val_bag_output_loss: 0.9292 - val_footwear_output_loss: 0.9351 - val_pose_output_loss: 0.6084 - val_emotion_output_loss: 0.9993 - val_gender_output_acc: 0.8326 - val_image_quality_output_acc: 0.5186 - val_age_output_acc: 0.3705 - val_weight_output_acc: 0.5952 - val_bag_output_acc: 0.6358 - val_footwear_output_acc: 0.6071 - val_pose_output_acc: 0.7928 - val_emotion_output_acc: 0.6722\n",
            "Epoch 95/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.001.\n",
            "338/339 [============================>.] - ETA: 0s - loss: 4.4829 - gender_output_loss: 0.1780 - image_quality_output_loss: 0.7123 - age_output_loss: 0.9991 - weight_output_loss: 0.6350 - bag_output_loss: 0.5268 - footwear_output_loss: 0.5533 - pose_output_loss: 0.2325 - emotion_output_loss: 0.6460 - gender_output_acc: 0.9283 - image_quality_output_acc: 0.6800 - age_output_acc: 0.5836 - weight_output_acc: 0.7396 - bag_output_acc: 0.7851 - footwear_output_acc: 0.7661 - pose_output_acc: 0.9072 - emotion_output_acc: 0.7553Learning rate:  0.001\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.4836 - gender_output_loss: 0.1777 - image_quality_output_loss: 0.7123 - age_output_loss: 0.9989 - weight_output_loss: 0.6356 - bag_output_loss: 0.5261 - footwear_output_loss: 0.5536 - pose_output_loss: 0.2321 - emotion_output_loss: 0.6472 - gender_output_acc: 0.9284 - image_quality_output_acc: 0.6801 - age_output_acc: 0.5836 - weight_output_acc: 0.7389 - bag_output_acc: 0.7856 - footwear_output_acc: 0.7661 - pose_output_acc: 0.9074 - emotion_output_acc: 0.7548 - val_loss: 7.5433 - val_gender_output_loss: 0.4656 - val_image_quality_output_loss: 1.0194 - val_age_output_loss: 1.5026 - val_weight_output_loss: 1.0617 - val_bag_output_loss: 0.9384 - val_footwear_output_loss: 0.9447 - val_pose_output_loss: 0.6156 - val_emotion_output_loss: 0.9952 - val_gender_output_acc: 0.8248 - val_image_quality_output_acc: 0.5197 - val_age_output_acc: 0.3638 - val_weight_output_acc: 0.6004 - val_bag_output_acc: 0.6269 - val_footwear_output_acc: 0.6023 - val_pose_output_acc: 0.7842 - val_emotion_output_acc: 0.6708\n",
            "Epoch 96/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 112ms/step - loss: 4.4531 - gender_output_loss: 0.1661 - image_quality_output_loss: 0.7081 - age_output_loss: 0.9923 - weight_output_loss: 0.6348 - bag_output_loss: 0.5197 - footwear_output_loss: 0.5592 - pose_output_loss: 0.2254 - emotion_output_loss: 0.6475 - gender_output_acc: 0.9309 - image_quality_output_acc: 0.6799 - age_output_acc: 0.5817 - weight_output_acc: 0.7396 - bag_output_acc: 0.7887 - footwear_output_acc: 0.7613 - pose_output_acc: 0.9145 - emotion_output_acc: 0.7562 - val_loss: 7.5655 - val_gender_output_loss: 0.4808 - val_image_quality_output_loss: 1.0225 - val_age_output_loss: 1.4938 - val_weight_output_loss: 1.0647 - val_bag_output_loss: 0.9422 - val_footwear_output_loss: 0.9444 - val_pose_output_loss: 0.6129 - val_emotion_output_loss: 1.0041 - val_gender_output_acc: 0.8263 - val_image_quality_output_acc: 0.5290 - val_age_output_acc: 0.3832 - val_weight_output_acc: 0.6042 - val_bag_output_acc: 0.6280 - val_footwear_output_acc: 0.6049 - val_pose_output_acc: 0.7879 - val_emotion_output_acc: 0.6730\n",
            "Epoch 97/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.4596 - gender_output_loss: 0.1703 - image_quality_output_loss: 0.7120 - age_output_loss: 0.9866 - weight_output_loss: 0.6343 - bag_output_loss: 0.5282 - footwear_output_loss: 0.5415 - pose_output_loss: 0.2362 - emotion_output_loss: 0.6506 - gender_output_acc: 0.9295 - image_quality_output_acc: 0.6790 - age_output_acc: 0.5895 - weight_output_acc: 0.7449 - bag_output_acc: 0.7821 - footwear_output_acc: 0.7698 - pose_output_acc: 0.9083 - emotion_output_acc: 0.7573 - val_loss: 7.5517 - val_gender_output_loss: 0.4642 - val_image_quality_output_loss: 1.0173 - val_age_output_loss: 1.5055 - val_weight_output_loss: 1.0641 - val_bag_output_loss: 0.9338 - val_footwear_output_loss: 0.9435 - val_pose_output_loss: 0.6122 - val_emotion_output_loss: 1.0112 - val_gender_output_acc: 0.8315 - val_image_quality_output_acc: 0.5275 - val_age_output_acc: 0.3780 - val_weight_output_acc: 0.5964 - val_bag_output_acc: 0.6373 - val_footwear_output_acc: 0.6049 - val_pose_output_acc: 0.7909 - val_emotion_output_acc: 0.6548\n",
            "Epoch 98/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.001.\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.4417 - gender_output_loss: 0.1700 - image_quality_output_loss: 0.7085 - age_output_loss: 0.9903 - weight_output_loss: 0.6311 - bag_output_loss: 0.5120 - footwear_output_loss: 0.5561 - pose_output_loss: 0.2324 - emotion_output_loss: 0.6414 - gender_output_acc: 0.9307 - image_quality_output_acc: 0.6757 - age_output_acc: 0.5880 - weight_output_acc: 0.7398 - bag_output_acc: 0.7898 - footwear_output_acc: 0.7643 - pose_output_acc: 0.9110 - emotion_output_acc: 0.7577 - val_loss: 7.6173 - val_gender_output_loss: 0.4810 - val_image_quality_output_loss: 1.0489 - val_age_output_loss: 1.5052 - val_weight_output_loss: 1.0634 - val_bag_output_loss: 0.9470 - val_footwear_output_loss: 0.9484 - val_pose_output_loss: 0.6183 - val_emotion_output_loss: 1.0051 - val_gender_output_acc: 0.8248 - val_image_quality_output_acc: 0.5100 - val_age_output_acc: 0.3735 - val_weight_output_acc: 0.6071 - val_bag_output_acc: 0.6310 - val_footwear_output_acc: 0.6038 - val_pose_output_acc: 0.7824 - val_emotion_output_acc: 0.6719\n",
            "Epoch 99/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.001.\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.001.\n",
            "339/339 [==============================] - 39s 114ms/step - loss: 4.4393 - gender_output_loss: 0.1719 - image_quality_output_loss: 0.7046 - age_output_loss: 0.9849 - weight_output_loss: 0.6292 - bag_output_loss: 0.5221 - footwear_output_loss: 0.5515 - pose_output_loss: 0.2284 - emotion_output_loss: 0.6467 - gender_output_acc: 0.9306 - image_quality_output_acc: 0.6826 - age_output_acc: 0.5889 - weight_output_acc: 0.7433 - bag_output_acc: 0.7895 - footwear_output_acc: 0.7639 - pose_output_acc: 0.9096 - emotion_output_acc: 0.7561 - val_loss: 7.6002 - val_gender_output_loss: 0.4810 - val_image_quality_output_loss: 1.0310 - val_age_output_loss: 1.5022 - val_weight_output_loss: 1.0683 - val_bag_output_loss: 0.9419 - val_footwear_output_loss: 0.9461 - val_pose_output_loss: 0.6198 - val_emotion_output_loss: 1.0098 - val_gender_output_acc: 0.8311 - val_image_quality_output_acc: 0.5201 - val_age_output_acc: 0.3802 - val_weight_output_acc: 0.6008 - val_bag_output_acc: 0.6376 - val_footwear_output_acc: 0.6042 - val_pose_output_acc: 0.7835 - val_emotion_output_acc: 0.6548\n",
            "Epoch 100/100\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 99/100Learning rate:  0.001\n",
            "339/339 [==============================] - 38s 113ms/step - loss: 4.4175 - gender_output_loss: 0.1704 - image_quality_output_loss: 0.7049 - age_output_loss: 0.9852 - weight_output_loss: 0.6280 - bag_output_loss: 0.5105 - footwear_output_loss: 0.5499 - pose_output_loss: 0.2282 - emotion_output_loss: 0.6403 - gender_output_acc: 0.9294 - image_quality_output_acc: 0.6798 - age_output_acc: 0.5873 - weight_output_acc: 0.7435 - bag_output_acc: 0.7946 - footwear_output_acc: 0.7706 - pose_output_acc: 0.9111 - emotion_output_acc: 0.7565 - val_loss: 7.5481 - val_gender_output_loss: 0.4592 - val_image_quality_output_loss: 1.0316 - val_age_output_loss: 1.5077 - val_weight_output_loss: 1.0644 - val_bag_output_loss: 0.9307 - val_footwear_output_loss: 0.9385 - val_pose_output_loss: 0.6170 - val_emotion_output_loss: 0.9990 - val_gender_output_acc: 0.8270 - val_image_quality_output_acc: 0.5175 - val_age_output_acc: 0.3735 - val_weight_output_acc: 0.6060 - val_bag_output_acc: 0.6332 - val_footwear_output_acc: 0.6083 - val_pose_output_acc: 0.7850 - val_emotion_output_acc: 0.6678\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.001.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faaa006d3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}